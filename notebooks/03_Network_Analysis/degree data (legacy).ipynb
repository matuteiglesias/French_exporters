{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import modules\n",
    "\n",
    "import pandas as pd\n",
    "# from IPython.display import display, HTML\n",
    "# from numpy import log10, nan, inf, random, clip, arange\n",
    "\n",
    "# path = './../export_france/data/type1/DP1610_MAASTRICHT1_1997_2013'\n",
    "\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "from numpy import arange, log10\n",
    "\n",
    "from functions import chunk, agg, finalize\n",
    "tunique = dd.Aggregation('tunique', chunk, agg,finalize)\n",
    "first = dd.Aggregation('first', chunk, agg,finalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd.read_csv('2014-*.csv')\n",
    "\n",
    "# drive_path = './../export_france/data/type1/DP1610_MAASTRICHT1_1997_2013'\n",
    "drive_path = './../../../../media/miglesia/Elements/export_france/data/type1/DP1610_MAASTRICHT1_1997_2013'\n",
    "\n",
    "n_bins = 20\n",
    "df_list = n_bins * [ 0 ]\n",
    "\n",
    "for dataset_i in range(n_bins):\n",
    "    df_list[dataset_i] = dd.read_csv(drive_path+'/samplings/YMxpb_size20'+str(dataset_i).zfill(2)+'.csv',\n",
    "                                    usecols = ['YEAR','ID','VAT','VART_sum'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dd.concat(df_list)\n",
    "data = data.groupby(['YEAR','ID','VAT'])['VART_sum'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  4min 57.9s\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    out = data.compute()\n",
    "\n",
    "data = dd.from_pandas(out, npartitions = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firm_sizes = log10(data.groupby(['ID', 'YEAR'])['VART_sum'].sum().reset_index().groupby('ID')[['VART_sum']].mean().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.compute().to_csv('buyer_seller_links.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1997\n",
      "[###############                         ] | 37% Completed | 22.9s"
     ]
    }
   ],
   "source": [
    "# window = 3\n",
    "# assortativity_res = []\n",
    "ID_degree_res = []\n",
    "VAT_degree_res = []\n",
    "\n",
    "for window in [5, 1, 3]:\n",
    "    gap = (window-1)/2\n",
    "    center_years = arange(1997, 2014, 2)\n",
    "    print window\n",
    "\n",
    "    for Yc in center_years:\n",
    "        print Yc\n",
    "        data_sec = data.loc[data.YEAR - Yc <= gap]\n",
    "#         data_sec.groupby(['ID', 'VAT']).agg({'CN ID 8': tunique, 'VART_sum': sum })\n",
    "\n",
    "        data_sec_by_ID = data_sec.groupby(['ID']).agg({'VAT': tunique, 'VART_sum': sum})\n",
    "\n",
    "        ID_degree = data_sec_by_ID[['VAT']].reset_index()\n",
    "        ID_degree.columns = [u'ID', u'ID_degree']\n",
    "        ID_degree['center_year'] = Yc\n",
    "        ID_degree['window'] = window\n",
    "        \n",
    "        with ProgressBar():\n",
    "            ID_deg = ID_degree.compute()\n",
    "            ID_deg['bin'] = pd.cut(log10(ID_deg['ID_degree']), bins = arange(-.49, 5.99, .25))\n",
    "            ID_deg.to_csv('ID_deg_'+str(Yc)+'_'+str(window))\n",
    "#         ID_degree_res += [ID_degree]     \n",
    "\n",
    "#         ID_deg = pd.read_csv()\n",
    "        sampling = ID_deg.groupby(['bin'], observed = True).apply(lambda x: x.sample(200, replace = True))\n",
    "\n",
    "        data_sec_sample = data_sec.loc[data_sec.ID.isin(sampling['ID'].values)]\n",
    "        data_sec_by_VAT = data_sec_sample.groupby(['VAT']).agg({'ID': tunique, 'VART_sum': sum})\n",
    "\n",
    "        VAT_degree = data_sec_by_VAT[['ID']].reset_index()\n",
    "        VAT_degree.columns = [u'VAT', u'VAT_degree']\n",
    "        VAT_degree['center_year'] = Yc\n",
    "        VAT_degree['window'] = window\n",
    "        VAT_degree_res += [VAT_degree]\n",
    "        with ProgressBar():\n",
    "            VAT_deg = VAT_degree.compute()\n",
    "            VAT_deg.to_csv('VAT_deg_save_'+str(Yc)+'_'+str(window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1997\n",
      "[########################################] | 100% Completed |  2min  2.6s\n",
      "1999\n",
      "[########################################] | 100% Completed |  3min 33.6s\n",
      "2001\n",
      "[########################################] | 100% Completed |  5min 35.0s\n",
      "2003\n",
      "[########################################] | 100% Completed |  6min 59.7s\n",
      "2005\n",
      "[########################################] | 100% Completed |  9min 48.0s\n",
      "2007\n",
      "[########################################] | 100% Completed | 12min 26.0s\n",
      "2009\n",
      "[########################################] | 100% Completed | 15min  1.5s\n",
      "2011\n",
      "[########################################] | 100% Completed | 18min 18.1s\n",
      "2013\n",
      "[########################################] | 100% Completed | 18min  7.1s\n",
      "3\n",
      "1997\n",
      "[########################################] | 100% Completed |  2min 16.9s\n",
      "1999\n",
      "[########################################] | 100% Completed |  3min 23.8s\n",
      "2001\n",
      "[########################################] | 100% Completed |  5min 24.9s\n",
      "2003\n",
      "[########################################] | 100% Completed |  6min  7.3s\n",
      "2005\n",
      "[########################################] | 100% Completed |  7min  4.8s\n",
      "2007\n",
      "[########################################] | 100% Completed | 14min 56.3s\n",
      "2009\n",
      "[########################################] | 100% Completed | 16min  8.0s\n",
      "2011\n",
      "[####################################### ] | 98% Completed | 11min  5.2s"
     ]
    }
   ],
   "source": [
    "VAT_degree_res = []\n",
    "for window in [1, 3, 5]:\n",
    "    gap = (window-1)/2\n",
    "    center_years = arange(1997, 2014, 2)\n",
    "    print window\n",
    "\n",
    "    for Yc in center_years:\n",
    "    \n",
    "        ID_deg = pd.read_csv('./ID_deg_save.csv')\n",
    "        ID_deg = ID_deg.loc[(ID_deg.center_year == Yc) & (ID_deg.window == window)]\n",
    "        ID_deg['bin'] = pd.cut(log10(ID_deg['ID_degree']), bins = arange(-.49, 5.99, .25))\n",
    "        sampling = ID_deg.groupby(['bin'], observed = True).apply(lambda x: x.sample(50, replace = True))\n",
    "\n",
    "        data_sec_sample = data_sec.loc[data_sec.ID.isin(sampling['ID'].values)]\n",
    "        data_sec_by_VAT = data_sec_sample.groupby(['VAT']).agg({'ID': tunique, 'VART_sum': sum})\n",
    "\n",
    "        VAT_degree = data_sec_by_VAT[['ID']].reset_index()\n",
    "        VAT_degree.columns = [u'VAT', u'VAT_degree']\n",
    "        VAT_degree['center_year'] = Yc\n",
    "        VAT_degree['window'] = window\n",
    "        VAT_degree_res += [VAT_degree]\n",
    "        with ProgressBar():\n",
    "            VAT_deg = VAT_degree.compute()\n",
    "            VAT_deg.to_csv('VAT_deg_save_'+str(Yc)+'_'+str(window))\n",
    "\n",
    "#         assortativity_info = data_sec_sample.groupby(['ID', 'VAT'])[['VART_sum']].mean().reset_index().merge(\n",
    "#             ID_degree).merge(VAT_degree)\n",
    "#         assortativity_res += [assortativity_info]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID_degree['bin'] = \n",
    "# pd.cut(log10(ID_degree['ID_degree']), bins = arange(-.49, 5.99, .5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID_deg_res = dd.concat(ID_degree_res)\n",
    "# with ProgressBar():\n",
    "#     ID_deg = ID_deg_res.compute()\n",
    "\n",
    "VAT_deg_res = dd.concat(VAT_degree_res)\n",
    "with ProgressBar():\n",
    "    VAT_deg = VAT_deg_res.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ID_deg.to_csv('./ID_deg_save.csv', index = False)\n",
    "VAT_deg.to_csv('./VAT_deg_save.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(log10(ID_deg['ID_degree']), bins = arange(-.49, 5.99, .25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# data_sec_sample.merge(ID_deg).merge(VAT_deg).compute()\n",
    "assortativity_info = data_sec_sample.groupby(['ID', 'VAT'])[['VART_sum']].mean().reset_index().merge(\n",
    "        ID_degree).merge(VAT_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with ProgressBar():\n",
    "    assortativity_df = assortativity_info.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assortativity_info.groupby(pd.cut(log10(assortativity_info['ID_degree']), bins = arange(-.49, 5.99, .5)))#['VAT_degree'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ID_deg['bin'] = pd.cut(log10(ID_deg['ID_degree']), bins = arange(-.49, 5.99, .5))\n",
    "ID_deg.groupby(['center_year','bin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sec_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID_deg.to_csv('degree_values.csv', index = False)\n",
    "\n",
    "from numpy import power\n",
    "left = power(10, arange(-.1, 5, .2)).round(1)\n",
    "right = power(10, arange(-.1, 5, .2) + .2).round(1)\n",
    "bins = pd.IntervalIndex.from_arrays(left, right)\n",
    "\n",
    "ID_deg_part = ID_deg.loc[(ID_deg.center_year == Yc) & (ID_deg.window == window)]\n",
    "ID_deg_part.groupby(pd.cut(ID_deg_part['ID_degree'], bins), observed = True).count().sort_index()\n",
    "\n",
    "sample_IDs = ID_deg_part.groupby(pd.cut(ID_deg_part['ID_degree'], bins), observed = True).apply(lambda x: x.sample(1000, replace = True))['ID'].values\n",
    "\n",
    "data_sec = data.loc[(data.YEAR - Yc <= gap) & (data.ID.isin(sample_IDs))]\n",
    "\n",
    "    \n",
    "#.apply(lambda x: x.sample(5000, replace = True))['ID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_results = []\n",
    "\n",
    "for df_degrees in results:\n",
    "\n",
    "    with ProgressBar():\n",
    "        x = df_degrees.compute()\n",
    "\n",
    "    summary_result = x.groupby(pd.cut(x['ID_degree'], bins)).agg({'VART_sum': 'sum', 'ID_degree': 'mean',\n",
    "                                            'VAT_degree': 'describe', 'center_year' : 'median', 'window': 'median'})\n",
    "    summary_results += [summary_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat(summary_results).dropna().to_csv('./assortativity_2000_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat(summary_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(summary_results).dropna().to_csv('./assortativity_2000_8plus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = dd.concat(results, axis = 1)\n",
    "\n",
    "\n",
    "with ProgressBar():\n",
    "    out_2 = res.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "df_degrees.groupby('VAT_degree_bin')['ID_degree','VAT_degree'].quantile(.25).plot(x = 'VAT_degree', y = 'ID_degree', marker = '', ax = ax)\n",
    "df_degrees.groupby('VAT_degree_bin')['ID_degree','VAT_degree'].quantile(.5).plot(x = 'VAT_degree', y = 'ID_degree', marker = '', ax = ax)\n",
    "df_degrees.groupby('VAT_degree_bin')['ID_degree','VAT_degree'].quantile(.75).plot(x = 'VAT_degree', y = 'ID_degree', marker = '', ax = ax)\n",
    "\n",
    "# df_degrees.groupby('ID_nunique_bin')['VAT_nunique','ID_nunique'].mean().plot(x = 'ID_nunique', y = 'VAT_nunique', marker = 'o', ax = ax)\n",
    "df_degrees.groupby('ID_nunique')['VAT_nunique'].median().plot(x = 'index', y = 'VAT_nunique', marker = '.', linewidth = 0, ax = ax)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### Choose a bin_size, \n",
    "# size_df_list = n_size_bins * [ None ]\n",
    "\n",
    "# for s in range(14, n_size_bins):\n",
    "\n",
    "#     bs_ix_df = exp_index.loc[exp_index.size_bins == s]\n",
    "\n",
    "#     size_i_df_list = []\n",
    "#     for dataset_i in bs_ix_df.exp_mma_cat.unique():\n",
    "#         df = df_list[dataset_i]\n",
    "#         size_i_df_list += [df.loc[df.ID.isin(bs_ix_df.ID)]]\n",
    "\n",
    "#         size_df_list[s] = pd.concat(size_i_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
