{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nbformat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nbformat\n",
    "\n",
    "def extract_notebook_content(notebook_path):\n",
    "    \"\"\"\n",
    "    Extracts content from a Jupyter notebook.\n",
    "    For this example, we are extracting all markdown cells and code comments.\n",
    "    \"\"\"\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as file:\n",
    "        notebook = nbformat.read(file, as_version=4)\n",
    "        content = []\n",
    "\n",
    "        for cell in notebook.cells:\n",
    "            if cell.cell_type == 'markdown':\n",
    "                content.append(cell.source)\n",
    "            elif cell.cell_type == 'code':\n",
    "                # Extracting comments from code cells\n",
    "                comments = [line for line in cell.source.split('\\n') if line.strip().startswith('#')]\n",
    "                content.extend(comments)\n",
    "\n",
    "        return '\\n'.join(content)\n",
    "\n",
    "project_directory = './02_Statistical_Analysis_and_Modeling/Thesis/'  # Replace with the path to your project directory\n",
    "notebooks_content = {}\n",
    "\n",
    "for file in os.listdir(project_directory):\n",
    "    if file.endswith('.ipynb'):\n",
    "        notebook_path = os.path.join(project_directory, file)\n",
    "        notebooks_content[file] = extract_notebook_content(notebook_path)\n",
    "\n",
    "# At this point, 'notebooks_content' contains the extracted content from each notebook\n",
    "# You can now proceed to analyze this content as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prompt_text = \"\"\"\n",
    "Hello, I have a series of Jupyter notebooks as part of a data analysis project on French exporters. I need an in-depth and technically detailed analysis of this notebook to understand its role in the overall project. For this notebook, please provide the following information with specific examples and critical evaluation:\n",
    "\n",
    "    Main Objective and Scope:\n",
    "        - What is the primary focus or research question addressed in this notebook?\n",
    "        - Identify the specific dataset(s) or data types analyzed. Please provide details on the nature and structure of these datasets.\n",
    "\n",
    "    Methodological Approach:\n",
    "        - Give a detailed overview of the analytical methods, algorithms, or models used. How do these approaches specifically apply to the data and objectives?\n",
    "        - Describe in detail the data processing and analysis techniques applied. Are these techniques standard in the field, or are they novel or unconventional?\n",
    "\n",
    "    Key Findings or Results:\n",
    "        - Summarize the significant results, insights, or conclusions derived from the analysis. Please include specific examples or excerpts from the notebook.\n",
    "        - Discuss any visualizations or charts used. How do they contribute to illustrating the findings? Are they effectively designed?\n",
    "\n",
    "    Areas for Improvement or Updates:\n",
    "        - Critically evaluate areas where this notebook could be updated or improved. Are there outdated methods, lack of comments, or inefficient code segments?\n",
    "        - Recommend specific additional analyses or data that could enhance the notebook's value. How would these changes impact the overall findings?\n",
    "\n",
    "    Potential Integrations or Relationships:\n",
    "        - Suggest how this notebook could be integrated with or related to other notebooks in the project. Are there overlapping or complementary aspects?\n",
    "        - Identify potential gaps in the current analysis that might be filled by other analyses or data sources.\n",
    "\n",
    "    General Observations:\n",
    "        - Provide any additional observations or notes that could be relevant for restructuring the project. Highlight format inconsistencies, missing data, or areas lacking in clarity.\n",
    "\n",
    "    Code Analysis (if applicable):\n",
    "        - Provide a detailed review of the code quality, efficiency, and potential areas for optimization or refactoring.\n",
    "\n",
    "Please structure your response with clear headings for each section and be as detailed and technical as possible. \n",
    "\n",
    "Notebook Content: {}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \"\"\"\n",
    "Hello, I have a series of Jupyter notebooks as part of a data analysis project on French exporters. I need an in-depth and technically detailed analysis of this notebook to understand its role in the overall project. For this notebook, please provide the following information with specific examples and critical evaluation:\n",
    "\n",
    "    Main Objective and Scope:\n",
    "        - What is the primary focus or research question addressed in this notebook?\n",
    "        - Identify the specific dataset(s) or data types analyzed. Please provide details on the nature and structure of these datasets.\n",
    "\n",
    "    Methodological Approach:\n",
    "        - Give a detailed overview of the analytical methods, algorithms, or models used. How do these approaches specifically apply to the data and objectives?\n",
    "        - Describe in detail the data processing and analysis techniques applied. Are these techniques standard in the field, or are they novel or unconventional?\n",
    "\n",
    "    Key Findings or Results:\n",
    "        - Summarize the significant results, insights, or conclusions derived from the analysis. Please include specific examples or excerpts from the notebook.\n",
    "        - Discuss any visualizations or charts used. How do they contribute to illustrating the findings? Are they effectively designed?\n",
    "\n",
    "    Areas for Improvement or Updates:\n",
    "        - Critically evaluate areas where this notebook could be updated or improved. Are there outdated methods, lack of comments, or inefficient code segments?\n",
    "        - Recommend specific additional analyses or data that could enhance the notebook's value. How would these changes impact the overall findings?\n",
    "\n",
    "    Potential Integrations or Relationships:\n",
    "        - Suggest how this notebook could be integrated with or related to other notebooks in the project. Are there overlapping or complementary aspects?\n",
    "        - Identify potential gaps in the current analysis that might be filled by other analyses or data sources.\n",
    "\n",
    "    General Observations:\n",
    "        - Provide any additional observations or notes that could be relevant for restructuring the project. Highlight format inconsistencies, missing data, or areas lacking in clarity.\n",
    "\n",
    "    Code Analysis (if applicable):\n",
    "        - Provide a detailed review of the code quality, efficiency, and potential areas for optimization or refactoring.\n",
    "\n",
    "Please structure your response with clear headings for each section and be as detailed and technical as possible. \n",
    "\n",
    "Notebook Content: {}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_text = \"\"\"\n",
    "# Please provide a condensed technical summary of the following Jupyter notebook. \n",
    "# Focus on highlighting key computational and scientific aspects, including specific Python packages, statistical methods, mathematical models, and thematic elements related to economics or other relevant fields. \n",
    "# Aim for a balance between brevity and technical detail, summarizing the notebook's purpose in one sentence, followed by a list of technical keywords and concepts. Limit your response to 100 words.\n",
    "\n",
    "# Notebook Content: {}\n",
    "# \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_text = \"\"\"\n",
    "# Hello, I have a series of Jupyter notebooks as part of a data analysis project on French exporters. I require a detailed, code-centric analysis of this notebook to better integrate and optimize the overall project. For this notebook, please provide the following detailed technical evaluation:\n",
    "\n",
    "# 1. **Code Breakdown and Functionality:**\n",
    "#    - Examine each code cell and explain its functionality. How does each segment of code contribute to the notebook's objectives?\n",
    "#    - Identify dependencies between code cells. Are there cells that must be executed in a specific sequence? Highlight any interdependencies.\n",
    "\n",
    "# 2. **Data Handling and Processing:**\n",
    "#    - Detail the methods used for data handling and processing. What specific libraries or tools are employed, and how are they used to manipulate the data?\n",
    "#    - Discuss the efficiency and scalability of the data processing methods. Are there opportunities for optimization?\n",
    "\n",
    "# 3. **Analytical Techniques and Modeling:**\n",
    "#    - Elaborate on the analytical methods, algorithms, or models used. How are they implemented in the code, and how do they address the research questions?\n",
    "#    - Evaluate the appropriateness and effectiveness of the applied techniques. Suggest alternatives or improvements if necessary.\n",
    "\n",
    "# 4. **Visualization and Results Presentation:**\n",
    "#    - Assess the visualizations and results presentation. How are the findings communicated through charts or tables in the notebook?\n",
    "#    - Provide suggestions for enhancing the clarity and impact of these visual elements.\n",
    "\n",
    "# 5. **Refactoring and Modularization:**\n",
    "#    - Critique the current structure of the notebook. Identify opportunities for refactoring and modularization.\n",
    "#    - Suggest functions or classes that can be extracted for better code reusability and readability.\n",
    "\n",
    "# 6. **Integration with Other Notebooks:**\n",
    "#    - Propose ways this notebook could be integrated with other notebooks in the project. Are there shared functions or data that can be centralized?\n",
    "#    - Recommend strategies for streamlining the overall project structure through consolidation or separation of notebook content.\n",
    "\n",
    "# 7. **Gap Analysis and Further Exploration:**\n",
    "#    - Point out any gaps in the analysis or areas that warrant further exploration.\n",
    "#    - How might additional data or alternative approaches enrich the existing analysis?\n",
    "\n",
    "# Please structure your response with detailed explanations and specific references to the notebook content. \n",
    "\n",
    "# Notebook Content: {}\n",
    "# \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_text = \"\"\"\n",
    "# Summarize the main purpose, methodologies, analysis methods used, and key themes of this Jupyter notebook. \n",
    "# Focus on critical functions, data analysis techniques, and specific subject areas. \n",
    "# Highlight essential functions and any specialized techniques or topics covered. \n",
    "# Provide a concise two to three-line summary. Limit the summary to two to three lines.\n",
    "# Notebook Content: {}\n",
    "# \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Experiment 3. Micro shocks. (s, gr).ipynb',\n",
       " 'Gabaix Equations Review.ipynb',\n",
       " 'Experiment 2. Extensive BME.ipynb',\n",
       " 'Experiment 4. Micro shocks. (s, gr, size dists).ipynb',\n",
       " 'Covariance Terms Bootstrap Experiments.ipynb',\n",
       " 'Experiment 1. Intensive. (N).ipynb',\n",
       " 'Parabolas. Simulated distribution and growth.ipynb',\n",
       " 'Test Exercise Gabaix Riccaboni.ipynb',\n",
       " 'Experiment 5. Simple var vs nq, s. (s).ipynb']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(notebooks_content.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 3. Micro shocks. (s, gr).ipynb\n",
      "Gabaix Equations Review.ipynb\n",
      "Experiment 2. Extensive BME.ipynb\n",
      "Experiment 4. Micro shocks. (s, gr, size dists).ipynb\n",
      "Covariance Terms Bootstrap Experiments.ipynb\n",
      "This model's maximum context length is 4097 tokens, however you requested 8663 tokens (7663 in your prompt; 1000 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing notebook: Covariance Terms Bootstrap Experiments.ipynb\n",
      "Experiment 1. Intensive. (N).ipynb\n",
      "This model's maximum context length is 4097 tokens, however you requested 5399 tokens (4399 in your prompt; 1000 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing notebook: Experiment 1. Intensive. (N).ipynb\n",
      "Parabolas. Simulated distribution and growth.ipynb\n",
      "Test Exercise Gabaix Riccaboni.ipynb\n",
      "Experiment 5. Simple var vs nq, s. (s).ipynb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./../../Notes/summary_code_nbs_thesis.md'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Assuming the 'notebooks_content' variable is already populated with the notebook contents\n",
    "# and you have set up your OpenAI API key in your environment\n",
    "\n",
    "# Choose two notebooks for the analysis\n",
    "selected_notebooks = list(notebooks_content.keys())\n",
    "\n",
    "# Initialize an empty string to store the combined API responses\n",
    "api_responses = \"\"\n",
    "openai.api_key = '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'\n",
    "\n",
    "\n",
    "# Process each selected notebook\n",
    "for nb in selected_notebooks:\n",
    "    try:\n",
    "        print(nb)\n",
    "        # Generate the prompt\n",
    "        prompt = prompt_text.format(notebooks_content[nb])\n",
    "\n",
    "        # Call the OpenAI API (this is a dummy call, as API access is not available in this environment)\n",
    "        response = openai.Completion.create(engine=\"text-davinci-003\", prompt=prompt, max_tokens=1000, )\n",
    "        # response = openai.Completion.create(engine=\"gpt-4-0613\", prompt=prompt, max_tokens=500)\n",
    "        api_responses += f\"Notebook: {nb}\\nResponse: {response.choices[0].text}\\n\\n\"\n",
    "\n",
    "        # # Since we can't actually call the API, let's simulate a response\n",
    "        # simulated_response = f\"Simulated analysis for notebook: {nb}\\n\"\n",
    "        # api_responses += simulated_response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Error processing notebook: {nb}\")\n",
    "\n",
    "# Write the responses to a file\n",
    "api_notes_filename = './../../Notes/summary_code_nbs_thesis.md'\n",
    "with open(api_notes_filename, 'w') as file:\n",
    "    file.write(api_responses)\n",
    "\n",
    "api_notes_filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./API_notes_2.md'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the responses to a file\n",
    "api_notes_filename = './API_notes_2.md'\n",
    "with open(api_notes_filename, 'w') as file:\n",
    "    file.write(api_responses)\n",
    "\n",
    "api_notes_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"2346pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 2346.08 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-184 2342.08,-184 2342.08,4 -4,4\"/>\n",
       "<!-- Covariance Terms Bootstrap Experiments -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Covariance Terms Bootstrap Experiments</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2119.09\" cy=\"-90\" rx=\"159.47\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2119.09\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Covariance Terms Bootstrap Experiments</text>\n",
       "</g>\n",
       "<!-- components_crosscov.png -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>components_crosscov.png</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2234.09\" cy=\"-18\" rx=\"103.98\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2234.09\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">components_crosscov.png</text>\n",
       "</g>\n",
       "<!-- Covariance Terms Bootstrap Experiments&#45;&gt;components_crosscov.png -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Covariance Terms Bootstrap Experiments&#45;&gt;components_crosscov.png</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2146.64,-72.23C2162.11,-62.81 2181.6,-50.95 2198.25,-40.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2200.44,-43.58 2207.17,-35.39 2196.8,-37.6 2200.44,-43.58\"/>\n",
       "</g>\n",
       "<!-- power_sums_vs_sigma.png -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>power_sums_vs_sigma.png</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2003.09\" cy=\"-18\" rx=\"109.38\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2003.09\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">power_sums_vs_sigma.png</text>\n",
       "</g>\n",
       "<!-- Covariance Terms Bootstrap Experiments&#45;&gt;power_sums_vs_sigma.png -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Covariance Terms Bootstrap Experiments&#45;&gt;power_sums_vs_sigma.png</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2091.31,-72.23C2075.81,-62.88 2056.32,-51.12 2039.61,-41.04\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2041.02,-37.8 2030.65,-35.63 2037.4,-43.79 2041.02,-37.8\"/>\n",
       "</g>\n",
       "<!-- Experiment 1. Intensive. (N) -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Experiment 1. Intensive. (N)</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"113.09\" cy=\"-90\" rx=\"113.18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"113.09\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Experiment 1. Intensive. (N)</text>\n",
       "</g>\n",
       "<!-- N_decay.png -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>N_decay.png</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"113.09\" cy=\"-18\" rx=\"57.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"113.09\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">N_decay.png</text>\n",
       "</g>\n",
       "<!-- Experiment 1. Intensive. (N)&#45;&gt;N_decay.png -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>Experiment 1. Intensive. (N)&#45;&gt;N_decay.png</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M113.09,-71.7C113.09,-63.98 113.09,-54.71 113.09,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"116.59,-46.1 113.09,-36.1 109.59,-46.1 116.59,-46.1\"/>\n",
       "</g>\n",
       "<!-- Parabolas. Simulated distribution and growth -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Parabolas. Simulated distribution and growth</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"415.09\" cy=\"-90\" rx=\"170.87\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"415.09\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Parabolas. Simulated distribution and growth</text>\n",
       "</g>\n",
       "<!-- parabolas_fit.png -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>parabolas_fit.png</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"527.09\" cy=\"-18\" rx=\"72.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"527.09\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">parabolas_fit.png</text>\n",
       "</g>\n",
       "<!-- Parabolas. Simulated distribution and growth&#45;&gt;parabolas_fit.png -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>Parabolas. Simulated distribution and growth&#45;&gt;parabolas_fit.png</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M442.2,-72.05C457.39,-62.56 476.48,-50.63 492.7,-40.49\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"494.76,-43.34 501.38,-35.07 491.05,-37.4 494.76,-43.34\"/>\n",
       "</g>\n",
       "<!-- gabaix_growth_rates.png -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>gabaix_growth_rates.png</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"337.09\" cy=\"-18\" rx=\"100.18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"337.09\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">gabaix_growth_rates.png</text>\n",
       "</g>\n",
       "<!-- Parabolas. Simulated distribution and growth&#45;&gt;gabaix_growth_rates.png -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>Parabolas. Simulated distribution and growth&#45;&gt;gabaix_growth_rates.png</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M396.21,-72.05C386.34,-63.2 374.11,-52.22 363.33,-42.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"365.58,-39.86 355.8,-35.79 360.9,-45.07 365.58,-39.86\"/>\n",
       "</g>\n",
       "<!-- Test Exercise Gabaix Riccaboni -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>Test Exercise Gabaix Riccaboni</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"728.09\" cy=\"-90\" rx=\"124.28\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"728.09\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Test Exercise Gabaix Riccaboni</text>\n",
       "</g>\n",
       "<!-- test_fig_1.png -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>test_fig_1.png</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"728.09\" cy=\"-18\" rx=\"61.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"728.09\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">test_fig_1.png</text>\n",
       "</g>\n",
       "<!-- Test Exercise Gabaix Riccaboni&#45;&gt;test_fig_1.png -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>Test Exercise Gabaix Riccaboni&#45;&gt;test_fig_1.png</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M728.09,-71.7C728.09,-63.98 728.09,-54.71 728.09,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"731.59,-46.1 728.09,-36.1 724.59,-46.1 731.59,-46.1\"/>\n",
       "</g>\n",
       "<!-- Experiment 3. Micro shocks. (s, gr) -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>Experiment 3. Micro shocks. (s, gr)</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1009.09\" cy=\"-90\" rx=\"138.38\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1009.09\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Experiment 3. Micro shocks. (s, gr)</text>\n",
       "</g>\n",
       "<!-- experiment_3.csv -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>experiment_3.csv</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1009.09\" cy=\"-18\" rx=\"73.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1009.09\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">experiment_3.csv</text>\n",
       "</g>\n",
       "<!-- Experiment 3. Micro shocks. (s, gr)&#45;&gt;experiment_3.csv -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>Experiment 3. Micro shocks. (s, gr)&#45;&gt;experiment_3.csv</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1009.09,-71.7C1009.09,-63.98 1009.09,-54.71 1009.09,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1012.59,-46.1 1009.09,-36.1 1005.59,-46.1 1012.59,-46.1\"/>\n",
       "</g>\n",
       "<!-- Experiment 2. Extensive BME -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>Experiment 2. Extensive BME</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1286.09\" cy=\"-90\" rx=\"120.48\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1286.09\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Experiment 2. Extensive BME</text>\n",
       "</g>\n",
       "<!-- bs_base.csv -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>bs_base.csv</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1345.09\" cy=\"-18\" rx=\"52.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1345.09\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">bs_base.csv</text>\n",
       "</g>\n",
       "<!-- Experiment 2. Extensive BME&#45;&gt;bs_base.csv -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>Experiment 2. Extensive BME&#45;&gt;bs_base.csv</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1300.37,-72.05C1307.55,-63.54 1316.38,-53.07 1324.29,-43.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1327.17,-45.69 1330.94,-35.79 1321.82,-41.18 1327.17,-45.69\"/>\n",
       "</g>\n",
       "<!-- bs_totl.csv -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>bs_totl.csv</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1226.09\" cy=\"-18\" rx=\"48.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1226.09\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">bs_totl.csv</text>\n",
       "</g>\n",
       "<!-- Experiment 2. Extensive BME&#45;&gt;bs_totl.csv -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>Experiment 2. Extensive BME&#45;&gt;bs_totl.csv</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1271.57,-72.05C1264.09,-63.33 1254.84,-52.54 1246.64,-42.98\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1249.23,-40.62 1240.07,-35.31 1243.92,-45.18 1249.23,-40.62\"/>\n",
       "</g>\n",
       "<!-- Experiment 5. Simple var vs nq, s. (s) -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>Experiment 5. Simple var vs nq, s. (s)</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1571.09\" cy=\"-90\" rx=\"146.77\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1571.09\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Experiment 5. Simple var vs nq, s. (s)</text>\n",
       "</g>\n",
       "<!-- Gabaix Equations Review -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>Gabaix Equations Review</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1839.09\" cy=\"-90\" rx=\"102.88\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1839.09\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Gabaix Equations Review</text>\n",
       "</g>\n",
       "<!-- ID_Y.csv -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>ID_Y.csv</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1147.09\" cy=\"-162\" rx=\"43.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1147.09\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">ID_Y.csv</text>\n",
       "</g>\n",
       "<!-- ID_Y.csv&#45;&gt;Covariance Terms Bootstrap Experiments -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>ID_Y.csv&#45;&gt;Covariance Terms Bootstrap Experiments</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1190.27,-158.69C1310.75,-152.12 1660.79,-132.25 1951.09,-108 1965.95,-106.76 1981.53,-105.34 1996.97,-103.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1997.47,-107.33 2007.08,-102.89 1996.79,-100.36 1997.47,-107.33\"/>\n",
       "</g>\n",
       "<!-- ID_Y.csv&#45;&gt;Experiment 1. Intensive. (N) -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>ID_Y.csv&#45;&gt;Experiment 1. Intensive. (N)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1103.8,-159.72C972.68,-155.58 568.52,-140.87 235.09,-108 224.42,-106.95 213.24,-105.66 202.18,-104.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"202.43,-100.76 192.06,-102.95 201.53,-107.7 202.43,-100.76\"/>\n",
       "</g>\n",
       "<!-- ID_Y.csv&#45;&gt;Parabolas. Simulated distribution and growth -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>ID_Y.csv&#45;&gt;Parabolas. Simulated distribution and growth</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1105.11,-156.99C998.9,-146.83 716.01,-119.78 547.25,-103.64\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"547.34,-100.13 537.05,-102.66 546.67,-107.1 547.34,-100.13\"/>\n",
       "</g>\n",
       "<!-- ID_Y.csv&#45;&gt;Test Exercise Gabaix Riccaboni -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>ID_Y.csv&#45;&gt;Test Exercise Gabaix Riccaboni</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1107.29,-154.35C1040.84,-143.25 905.75,-120.68 816.07,-105.7\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"816.62,-102.24 806.18,-104.05 815.47,-109.15 816.62,-102.24\"/>\n",
       "</g>\n",
       "<!-- ID_Y.csv&#45;&gt;Experiment 3. Micro shocks. (s, gr) -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>ID_Y.csv&#45;&gt;Experiment 3. Micro shocks. (s, gr)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1120.48,-147.5C1100.73,-137.48 1073.4,-123.62 1050.76,-112.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1052.2,-108.94 1041.7,-107.54 1049.03,-115.18 1052.2,-108.94\"/>\n",
       "</g>\n",
       "<!-- ID_Y.csv&#45;&gt;Experiment 2. Extensive BME -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>ID_Y.csv&#45;&gt;Experiment 2. Extensive BME</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1173.56,-147.67C1193.57,-137.59 1221.42,-123.57 1244.41,-111.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1246.24,-114.99 1253.6,-107.36 1243.09,-108.73 1246.24,-114.99\"/>\n",
       "</g>\n",
       "<!-- ID_Y.csv&#45;&gt;Experiment 5. Simple var vs nq, s. (s) -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>ID_Y.csv&#45;&gt;Experiment 5. Simple var vs nq, s. (s)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1186.98,-154.41C1252.95,-143.52 1386.5,-121.47 1477.39,-106.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1478.13,-109.9 1487.42,-104.81 1476.99,-102.99 1478.13,-109.9\"/>\n",
       "</g>\n",
       "<!-- ID_Y.csv&#45;&gt;Gabaix Equations Review -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>ID_Y.csv&#45;&gt;Gabaix Equations Review</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1189.75,-157.98C1285.86,-150.97 1526.59,-132.36 1727.09,-108 1736.51,-106.86 1746.35,-105.54 1756.13,-104.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1756.88,-107.58 1766.28,-102.69 1755.88,-100.66 1756.88,-107.58\"/>\n",
       "</g>\n",
       "<!-- firms_data.csv -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>firms_data.csv</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"113.09\" cy=\"-162\" rx=\"63.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"113.09\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">firms_data.csv</text>\n",
       "</g>\n",
       "<!-- firms_data.csv&#45;&gt;Experiment 1. Intensive. (N) -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>firms_data.csv&#45;&gt;Experiment 1. Intensive. (N)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M113.09,-143.7C113.09,-135.98 113.09,-126.71 113.09,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"116.59,-118.1 113.09,-108.1 109.59,-118.1 116.59,-118.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f95be6b8090>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "dot = Digraph(comment='Notebooks Data Flow')\n",
    "\n",
    "# Defining Nodes (Notebooks)\n",
    "notebooks = [\"Covariance Terms Bootstrap Experiments\", \"Experiment 1. Intensive. (N)\", \n",
    "             \"Parabolas. Simulated distribution and growth\", \"Test Exercise Gabaix Riccaboni\", \n",
    "             \"Experiment 3. Micro shocks. (s, gr)\", \"Experiment 2. Extensive BME\", \n",
    "             \"Experiment 5. Simple var vs nq, s. (s)\", \"Gabaix Equations Review\"]\n",
    "\n",
    "for nb in notebooks:\n",
    "    dot.node(nb, nb)\n",
    "\n",
    "# Defining Data Source Nodes\n",
    "data_sources = [\"ID_Y.csv\", \"firms_data.csv\", \"experiment_3.csv\", \"bs_base.csv\", \"bs_totl.csv\"]\n",
    "for ds in data_sources:\n",
    "    dot.node(ds, ds)\n",
    "\n",
    "# Defining Data Flow\n",
    "# Covariance Terms Bootstrap Experiments Notebook\n",
    "dot.edges([(\"ID_Y.csv\", \"Covariance Terms Bootstrap Experiments\"), \n",
    "           (\"Covariance Terms Bootstrap Experiments\", \"components_crosscov.png\"), \n",
    "           (\"Covariance Terms Bootstrap Experiments\", \"power_sums_vs_sigma.png\")])\n",
    "\n",
    "# Experiment 1. Intensive. (N) Notebook\n",
    "dot.edges([(\"ID_Y.csv\", \"Experiment 1. Intensive. (N)\"), \n",
    "           (\"firms_data.csv\", \"Experiment 1. Intensive. (N)\"), \n",
    "           (\"Experiment 1. Intensive. (N)\", \"N_decay.png\")])\n",
    "\n",
    "# Parabolas. Simulated distribution and growth Notebook\n",
    "dot.edges([(\"ID_Y.csv\", \"Parabolas. Simulated distribution and growth\"), \n",
    "           (\"Parabolas. Simulated distribution and growth\", \"parabolas_fit.png\"), \n",
    "           (\"Parabolas. Simulated distribution and growth\", \"gabaix_growth_rates.png\")])\n",
    "\n",
    "# Test Exercise Gabaix Riccaboni Notebook\n",
    "dot.edges([(\"ID_Y.csv\", \"Test Exercise Gabaix Riccaboni\"), \n",
    "           (\"Test Exercise Gabaix Riccaboni\", \"test_fig_1.png\")])\n",
    "\n",
    "# Experiment 3. Micro shocks. (s, gr) Notebook\n",
    "dot.edges([(\"ID_Y.csv\", \"Experiment 3. Micro shocks. (s, gr)\"), \n",
    "           (\"Experiment 3. Micro shocks. (s, gr)\", \"experiment_3.csv\")])\n",
    "\n",
    "# Experiment 2. Extensive BME Notebook\n",
    "dot.edges([(\"ID_Y.csv\", \"Experiment 2. Extensive BME\"), \n",
    "           (\"Experiment 2. Extensive BME\", \"bs_base.csv\"), \n",
    "           (\"Experiment 2. Extensive BME\", \"bs_totl.csv\")])\n",
    "\n",
    "# Experiment 5. Simple var vs nq, s. (s) Notebook\n",
    "dot.edge(\"ID_Y.csv\", \"Experiment 5. Simple var vs nq, s. (s)\")\n",
    "\n",
    "# Gabaix Equations Review Notebook\n",
    "dot.edge(\"ID_Y.csv\", \"Gabaix Equations Review\")\n",
    "\n",
    "dot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
