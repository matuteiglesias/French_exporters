{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract from database\n",
    "\n",
    "This notebook contains all queries to the source database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import pandas as pd\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "from functions import chunk, agg, finalize\n",
    "tunique = dd.Aggregation('tunique', chunk, agg,finalize)\n",
    "first = dd.Aggregation('first', chunk, agg,finalize)\n",
    "\n",
    "# %load_ext autoreload\n",
    "from IPython.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_path = './../../../export_france/data/type1/DP1610_MAASTRICHT1_1997_2013/'\n",
    "# save_path = './../../../../../media/miglesia/Elements/export_france/data/processed/'\n",
    "save_path = './../../data/processed/'\n",
    "\n",
    "colnames = [u'YEAR', u'MONTH', u'FLUX', u'ID', u'DEPT', u'CN ID 8', u'CPA6',\n",
    "       u'PYOD', u'PAYP', u'VAT', u'PRIFAC', u'DEVFAC', u'VFTE', u'VART', u'D_MASSE', u'MASSE', u'USUP', u'USUP_MT']\n",
    "colname_no = dict(zip(colnames, range(18)))\n",
    "\n",
    "def get_data(columns, drive_path, start_year = 1997, end_year = 2014):\n",
    "    df_list = []\n",
    "    usecols = map(colname_no.get, columns)\n",
    "    no_colname = {v: k for k, v in colname_no.items()}\n",
    "\n",
    "    for y in range(start_year, end_year):\n",
    "        df_list += [dd.read_table(drive_path+'DP1610_MAASTRICHT1_'+str(y)+'.txt', \n",
    "                usecols = usecols,\n",
    "                delimiter = ';', header = None, dtype = {9: 'object'})]\n",
    "\n",
    "    data = dd.concat(df_list)\n",
    "    data.columns = [no_colname[k] for k in sorted(usecols)]\n",
    "    \n",
    "    data = data.loc[data.VART >= 1000] # This is to continue the effect of older thresholding after 2010\n",
    "\n",
    "    # map LU and BE to XU\n",
    "    if 'PYOD' in columns: data['PYOD'] = data['PYOD'].str.replace('BE', 'XU').str.replace('LU', 'XU')\n",
    "    if 'PAYP' in columns: data['PAYP'] = data['PAYP'].str.replace('BE', 'XU').str.replace('LU', 'XU')\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print for latex\n",
    "\n",
    "# df = get_data(colnames, drive_path, end_year = 1998)\n",
    "# print(df.sample(frac = 0.000001).compute().to_latex())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build datasets\n",
    "### - Price and quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 16min 39.3s\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 5] Input/output error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-fed10c072397>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mProgressBar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0myearly_qv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'VART'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MASSE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0myearly_qv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'units_qv.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# with ProgressBar():\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   1743\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 1745\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1747\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/site-packages/pandas/io/formats/csvs.pyc\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnicodeWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mwriter_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/site-packages/pandas/io/formats/csvs.pyc\u001b[0m in \u001b[0;36m_save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/site-packages/pandas/io/formats/csvs.pyc\u001b[0m in \u001b[0;36m_save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         libwriters.write_csv_rows(self.data, ix, self.nlevels,\n\u001b[1;32m--> 313\u001b[1;33m                                   self.cols, self.writer)\n\u001b[0m",
      "\u001b[1;32mpandas/_libs/writers.pyx\u001b[0m in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 5] Input/output error"
     ]
    }
   ],
   "source": [
    "# columns = [u'YEAR', u'MONTH', u'FLUX', u'ID', u'CN ID 8', u'PYOD', u'VART', u'MASSE', u'USUP', u'USUP_MT']\n",
    "\n",
    "# data_ = get_data(columns, drive_path, end_year = 2014)\n",
    "\n",
    "# grouped = data_.loc[data_.FLUX == 2].groupby(['ID', 'CN ID 8', 'MONTH', 'YEAR'])\n",
    "\n",
    "# with ProgressBar():\n",
    "#     yearly_qv = grouped[['VART', 'MASSE']].sum().compute()\n",
    "# yearly_qv.to_csv(save_path + 'units_qv.csv')\n",
    "\n",
    "# # with ProgressBar():\n",
    "# #     yearly_details = data_.loc[data_.FLUX == 2].head(1000).groupby(['ID', 'CN ID 8', 'YEAR']).agg(\n",
    "# #         {'VART': sum, 'MASSE': sum, 'USUP': tunique, 'USUP': first, 'USUP_MT': sum}).compute()\n",
    "# # yearly_details.to_csv(save_path + 'units_detail.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CN ID 8</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>VART</th>\n",
       "      <th>MASSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1029061</td>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>7621</td>\n",
       "      <td>5400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1029079</td>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>762</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7051105</td>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>1185</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>7052900</td>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>2398</td>\n",
       "      <td>2828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>7093000</td>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>919</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  CN ID 8  MONTH  YEAR  VART  MASSE\n",
       "0   0  1029061      1  1997  7621   5400\n",
       "1   0  1029079      1  1997   762    600\n",
       "2   0  7051105      1  1997  1185    454\n",
       "3   0  7052900      1  1997  2398   2828\n",
       "4   0  7093000      1  1997   919    502"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(save_path + 'units_qv.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Price and quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 12min 24.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miglesia/anaconda2/lib/python2.7/site-packages/dask/core.py:136: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  args2 = [_get_recursive(dsk, k, cache) for k in args]\n"
     ]
    }
   ],
   "source": [
    "columns = [u'YEAR', u'FLUX', u'ID', u'DEPT', 'CN ID 8', 'VART']\n",
    "data = get_data(columns, drive_path, end_year = 2014)\n",
    "\n",
    "data['IMPORT'] = data['FLUX'] % 2\n",
    "\n",
    "CN_full = pd.read_csv('./../data/CN_full.csv', encoding = 'utf-8')\n",
    "data = data.merge(CN_full[['CN ID 8', 'CN ID 4', 'CN label 4']])#.persist()\n",
    "\n",
    "data = data.groupby(['ID', 'CN ID 4', 'YEAR', 'DEPT'])[['VART']].sum().reset_index()\n",
    "\n",
    "with ProgressBar():\n",
    "    df = data.compute()\n",
    "\n",
    "df.to_csv(save_path + '_transactions_location.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Product comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 14min 18.7s\n"
     ]
    }
   ],
   "source": [
    "columns = [u'YEAR', u'FLUX', 'CN ID 8', 'CPA6', 'VART']\n",
    "\n",
    "data = get_data(columns, drive_path)\n",
    "data = data.loc[data.VART >= 1000] # This is to continue the effect of older thresholding after 2010\n",
    "\n",
    "\n",
    "data['IMPORT'] = data['FLUX'] % 2\n",
    "\n",
    "CN_full = pd.read_csv('./../../data/CN_full.csv', encoding = 'utf-8')\n",
    "\n",
    "data = data.merge(CN_full[['CN ID 8', 'CN ID 4', 'CN label 4']])#.persist()\n",
    "\n",
    "data = data.groupby(['CN ID 8', 'CN ID 4', 'CPA6', 'IMPORT', 'YEAR'])[['VART']].sum().reset_index()\n",
    "\n",
    "with ProgressBar():\n",
    "    df = data.compute()\n",
    "\n",
    "df.to_csv(save_path + 'product_compare.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Agregate each of the variables by year, month, flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 15min  6.8s\n"
     ]
    }
   ],
   "source": [
    "for col in ['CN ID 8']:#, 'CPA6', 'ID', 'VAT', 'DEPT', 'PYOD']:\n",
    "\n",
    "    columns = [u'YEAR', u'MONTH', u'FLUX', col, u'VART']\n",
    "    data = get_data(columns, drive_path)\n",
    "    data = data.loc[data.VART >= 1000] # This is to continue the effect of older thresholding after 2010\n",
    "\n",
    "    data['IMPORT'] = data['FLUX'] % 2\n",
    "\n",
    "#     agg = data.groupby([col, 'IMPORT','YEAR', 'MONTH'])[['VART']].sum().reset_index()\n",
    "#     with ProgressBar():\n",
    "#         agg = agg.compute()\n",
    "#     agg.to_csv(save_path + col.replace(' ', '_')+'_YM.csv', index = False)\n",
    "    \n",
    "    if col == 'CN ID 8':\n",
    "        CN_full = pd.read_csv('./../../data/CN_full.csv', encoding = 'utf-8')\n",
    "        data = data.merge(CN_full[['CN ID 8', 'CN ID 4', 'CN label 4']])#.persist()\n",
    "\n",
    "        agg = data.groupby(['CN ID 4', 'IMPORT', 'YEAR', 'MONTH'])[['VART']].sum().reset_index()\n",
    "\n",
    "        with ProgressBar():\n",
    "            agg = agg.compute()\n",
    "        agg.to_csv(save_path + 'CN ID 4'.replace(' ', '_')+'_YM.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Agregate each of the variables by year, flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\n",
      "[####                                    ] | 10% Completed |  1min 55.7s\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miglesia/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 1118, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/miglesia/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 300, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/miglesia/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/miglesia/anaconda2/lib/python2.7/inspect.py\", line 1051, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/home/miglesia/anaconda2/lib/python2.7/inspect.py\", line 1011, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/miglesia/anaconda2/lib/python2.7/inspect.py\", line 453, in getsourcefile\n",
      "    if hasattr(getmodule(object, filename), '__loader__'):\n",
      "  File \"/home/miglesia/anaconda2/lib/python2.7/inspect.py\", line 490, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/home/miglesia/anaconda2/lib/python2.7/site-packages/py/_apipkg.py\", line 171, in __getattribute__\n",
      "    return getattr(getmod(), name)\n",
      "  File \"/home/miglesia/anaconda2/lib/python2.7/site-packages/py/_apipkg.py\", line 155, in getmod\n",
      "    x = importobj(modpath, None)\n",
      "  File \"/home/miglesia/anaconda2/lib/python2.7/site-packages/py/_apipkg.py\", line 48, in importobj\n",
      "    module = __import__(modpath, None, None, ['__doc__'])\n",
      "  File \"/home/miglesia/anaconda2/lib/python2.7/site-packages/pytest.py\", line 27, in <module>\n",
      "    _preloadplugins() # to populate pytest.* namespace so help(pytest) works\n",
      "  File \"/home/miglesia/anaconda2/lib/python2.7/site-packages/_pytest/config.py\", line 75, in _preloadplugins\n",
      "    _preinit.append(get_config())\n",
      "  File \"/home/miglesia/anaconda2/lib/python2.7/site-packages/_pytest/config.py\", line 84, in get_config\n",
      "    pluginmanager.import_plugin(spec)\n",
      "  File \"/home/miglesia/anaconda2/lib/python2.7/site-packages/_pytest/config.py\", line 384, in import_plugin\n",
      "    __import__(importspec)\n",
      "  File \"/home/miglesia/anaconda2/lib/python2.7/site-packages/_pytest/junitxml.py\", line 44, in <module>\n",
      "    illegal_xml_re = re.compile(unicode('[^%s]') % unicode('').join(_legal_xml_re))\n",
      "  File \"/home/miglesia/anaconda2/lib/python2.7/re.py\", line 194, in compile\n",
      "    return _compile(pattern, flags)\n",
      "  File \"/home/miglesia/anaconda2/lib/python2.7/re.py\", line 249, in _compile\n",
      "    p = sre_compile.compile(pattern, flags)\n",
      "  File \"/home/miglesia/anaconda2/lib/python2.7/sre_compile.py\", line 576, in compile\n",
      "    code = _code(p, flags)\n",
      "  File \"/home/miglesia/anaconda2/lib/python2.7/sre_compile.py\", line 561, in _code\n",
      "    _compile(code, p.data, flags)\n",
      "  File \"/home/miglesia/anaconda2/lib/python2.7/sre_compile.py\", line 107, in _compile\n",
      "    _compile_charset(av, flags, code, fixup, fixes)\n",
      "  File \"/home/miglesia/anaconda2/lib/python2.7/sre_compile.py\", line 232, in _compile_charset\n",
      "    flags & SRE_FLAG_UNICODE):\n",
      "  File \"/home/miglesia/anaconda2/lib/python2.7/sre_compile.py\", line 274, in _optimize_charset\n",
      "    r = range(av[0], av[1]+1)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[1;34m(self, code_obj, result)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[0;32m   1828\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1829\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 1830\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   1831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1832\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1390\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1392\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1298\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1300\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1301\u001b[0m             )\n\u001b[0;32m   1302\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 \u001b[0mstructured_traceback_parts\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m             \u001b[0mstructured_traceback_parts\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstructured_traceback_parts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "for col in ['ID','CN ID 8', 'CPA6', 'VAT', 'DEPT', 'PYOD']:\n",
    "    print(col)\n",
    "    columns = [u'YEAR', u'FLUX', col, u'VART']\n",
    "    data = get_data(columns, drive_path)\n",
    "\n",
    "    data['IMPORT'] = data['FLUX'] % 2\n",
    "\n",
    "    agg = data.groupby([col, 'IMPORT','YEAR'])[['VART']].sum().reset_index()\n",
    "    with ProgressBar():\n",
    "        agg = agg.compute()\n",
    "    agg.to_csv(save_path + col.replace(' ', '_')+'_Y.csv', index = False)\n",
    "    \n",
    "    if col == 'CN ID 8':\n",
    "        CN_full = pd.read_csv('./../../data/CN_full.csv', encoding = 'utf-8')\n",
    "        data = data.merge(CN_full[['CN ID 8', 'CN ID 4', 'CN label 4']])#.persist()\n",
    "\n",
    "        agg = data.groupby(['CN ID 4', 'IMPORT', 'YEAR'])[['VART']].sum().reset_index()\n",
    "\n",
    "        with ProgressBar():\n",
    "            agg = agg.compute()\n",
    "        agg.to_csv(save_path + 'CN ID 4'.replace(' ', '_')+'_Y.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Agregate each of the variables by month, year, flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 14min 21.2s\n"
     ]
    }
   ],
   "source": [
    "for col in ['CN ID 8', 'CPA6', 'ID', 'VAT', 'DEPT', 'PYOD']:\n",
    "\n",
    "    columns = [u'YEAR', 'MONTH', u'FLUX', col, u'VART']\n",
    "    data = get_data(columns, drive_path)\n",
    "#     data = data.loc[data.VART >= 1000] # This is to continue the effect of older thresholding after 2010\n",
    "\n",
    "    data['IMPORT'] = data['FLUX'] % 2\n",
    "\n",
    "    agg = data.groupby([col, 'IMPORT','YEAR', 'MONTH'])[['VART']].sum().reset_index()\n",
    "    with ProgressBar():\n",
    "        agg = agg.compute()\n",
    "    agg.to_csv(save_path + col.replace(' ', '_')+'_YM.csv', index = False)\n",
    "    \n",
    "#     if col == 'CN ID 8':\n",
    "#         CN_full = pd.read_csv('./../../data/CN_full.csv', encoding = 'utf-8')\n",
    "#         data = data.merge(CN_full[['CN ID 8', 'CN ID 4', 'CN label 4']])#.persist()\n",
    "\n",
    "#         agg = data.groupby(['CN ID 4', 'IMPORT', 'YEAR'])[['VART']].sum().reset_index()\n",
    "\n",
    "#         with ProgressBar():\n",
    "#             agg = agg.compute()\n",
    "#         agg.to_csv(save_path + 'CN ID 4'.replace(' ', '_')+'_Y.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of products, destinations, buyers and FR places per firm-year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  8min 23.8s\n",
      "[########################################] | 100% Completed |  7min 50.4s\n",
      "[########################################] | 100% Completed |  8min 45.3s\n",
      "[########################################] | 100% Completed |  7min 46.1s\n",
      "[########################################] | 100% Completed |  8min 20.7s\n",
      "[########################################] | 100% Completed |  8min  2.1s\n"
     ]
    }
   ],
   "source": [
    "for col in ['CN ID 8', 'CPA6', 'PYOD', 'VAT', 'DEPT']:\n",
    "\n",
    "    columns = ['ID', u'YEAR', u'FLUX', col, u'VART']\n",
    "    data = get_data(columns, drive_path, start_year = 2006)\n",
    "    data = data.loc[data.VART >= 1000] # This is to continue the effect of older thresholding after 2010\n",
    "\n",
    "    data['IMPORT'] = data['FLUX'] % 2\n",
    "    \n",
    "    agg = data.groupby(['ID','YEAR', 'IMPORT', col])[['VART']].sum().reset_index()\n",
    "    with ProgressBar():\n",
    "        agg = agg.compute()\n",
    "    agg.to_csv(save_path + col.replace(' ', '_')+'_FY.csv', index = False)\n",
    "    \n",
    "    if col == 'CN ID 8':\n",
    "        CN_full = pd.read_csv('./../../data/CN_full.csv', encoding = 'utf-8')\n",
    "        data = data.merge(CN_full[['CN ID 8', 'CN ID 4', 'CN label 4']])#.persist()\n",
    "\n",
    "        agg = data.groupby(['ID','YEAR', 'IMPORT', 'CN ID 4'])[['VART']].sum().reset_index()\n",
    "\n",
    "        with ProgressBar():\n",
    "            agg = agg.compute()\n",
    "        agg.to_csv(save_path + 'CN ID 4'.replace(' ', '_')+'_FY.csv', index = False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Firm sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 11min 12.0s\n",
      "[########################################] | 100% Completed | 16min 56.9s\n"
     ]
    }
   ],
   "source": [
    "columns = [u'YEAR', u'MONTH', u'FLUX', u'ID', u'VAT', u'VART']\n",
    "data = get_data(columns, drive_path, end_year = 2014)\n",
    "data = data.loc[data.VART >= 1000] # This is to continue the effect of older thresholding after 2010\n",
    "\n",
    "\n",
    "data['IMPORT'] = data['FLUX'] % 2\n",
    "\n",
    "firm_sizes = data.groupby(['ID', 'IMPORT','YEAR'])[['VART']].sum().reset_index()\n",
    "buyr_sizes = data.groupby(['VAT', 'IMPORT','YEAR'])[['VART']].sum().reset_index()\n",
    "\n",
    "with ProgressBar():\n",
    "    firm_sizes = firm_sizes.compute()\n",
    "    buyr_sizes = buyr_sizes.compute()\n",
    "    \n",
    "\n",
    "firm_sizes.to_csv(save_path + 'firm_sizes.csv', index = False)\n",
    "buyr_sizes.to_csv(save_path + 'buyr_sizes.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset total (pool all years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 13min 29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miglesia/anaconda2/lib/python2.7/site-packages/dask/core.py:136: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  args2 = [_get_recursive(dsk, k, cache) for k in args]\n"
     ]
    }
   ],
   "source": [
    "columns = [u'FLUX', 'YEAR','CN ID 8', 'CPA6', 'PYOD', 'VAT', u'ID', u'VART']\n",
    "data = get_data(columns, drive_path, start_year = 2009)\n",
    "# data = data.loc[data.VART >= 1000] # This is to continue the effect of older thresholding after 2010\n",
    "\n",
    "data['IMPORT'] = data['FLUX'] % 2\n",
    "\n",
    "data['VAT'] = data['VAT'].fillna(data['PYOD'])\n",
    "CN_full = pd.read_csv('./../../data/CN_full.csv', encoding = 'utf-8')\n",
    "data = data.merge(CN_full[['CN ID 8', 'CN ID 4']])#.persist()\n",
    "        \n",
    "# data = data.groupby(['ID', 'IMPORT','CN ID 8', 'CN ID 4', 'CPA6', 'PYOD', 'VAT'])[['VART']].sum().reset_index()\n",
    "\n",
    "# Records within each year are summed\n",
    "yearly = data.groupby(['ID', 'IMPORT', 'CN ID 4','CPA6', 'CN ID 8', 'PYOD', 'VAT', 'YEAR'])[['VART']].sum().reset_index()\n",
    "yearly['PERIOD'] = (yearly.YEAR - 1997)//6\n",
    "\n",
    "# Yearly mean, in 3 periods, to relieve memory\n",
    "data = yearly.groupby(['ID', 'IMPORT', 'CN ID 4','CPA6', 'CN ID 8','PYOD', 'VAT', 'PERIOD'])[['VART']].mean().reset_index()\n",
    "\n",
    "with ProgressBar():\n",
    "    data = data.compute()\n",
    "    \n",
    "data.to_csv(save_path + '_FBCP.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Value of buyer-seller links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                        ] | 0% Completed |  6.6s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-189dba71a8c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mProgressBar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'buyer_seller_link_value.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/site-packages/dask/base.pyc\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[0mdask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \"\"\"\n\u001b[1;32m--> 156\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/site-packages/dask/base.pyc\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    393\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dask_keys__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m     \u001b[0mpostcomputes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/site-packages/dask/threaded.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(dsk, result, cache, num_workers, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m     results = get_async(pool.apply_async, len(pool._pool), dsk, result,\n\u001b[0;32m     74\u001b[0m                         \u001b[0mcache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_thread_get_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                         pack_exception=pack_exception, **kwargs)\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;31m# Cleanup pools associated to dead threads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/site-packages/dask/local.pyc\u001b[0m in \u001b[0;36mget_async\u001b[1;34m(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\u001b[0m\n\u001b[0;32m    490\u001b[0m             \u001b[1;31m# Main loop, wait on tasks to finish, insert new ones\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'waiting'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ready'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'running'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m                 \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfailed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m                     \u001b[0mexc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/site-packages/dask/local.pyc\u001b[0m in \u001b[0;36mqueue_get\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;31m# For more information see: https://bugs.python.org/issue1360\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m365\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m24\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m60\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'nt'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/Queue.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    175\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m             \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    357\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m                     \u001b[0mdelay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelay\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m                     \u001b[0m_sleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgotit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "columns = [u'YEAR', u'FLUX', u'ID', u'VAT', u'VART']\n",
    "\n",
    "data = get_data(columns, drive_path, start_year = 2005, end_year = 2014)\n",
    "data['IMPORT'] = data['FLUX'] % 2\n",
    "\n",
    "links = data.dropna().groupby(['IMPORT','YEAR','ID','VAT'])['VART'].sum().reset_index()\n",
    "\n",
    "with ProgressBar():\n",
    "    out = links.compute()\n",
    "    \n",
    "out.to_csv(save_path + 'buyer_seller_link_value.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(save_path + 'buyer_seller_link_value.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Sourcing info (QUARTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  6min 53.7s\n",
      "[########################################] | 100% Completed |  7min 37.7s\n"
     ]
    }
   ],
   "source": [
    "columns = [u'YEAR', u'MONTH', u'FLUX', u'ID', u'CN ID 8', 'PYOD', 'VAT', u'VART']\n",
    "\n",
    "data = get_data(columns, drive_path, end_year = 2004)\n",
    "data['VAT'] = data['VAT'].fillna(data['PYOD'])\n",
    "# data = data.loc[data.VART >= 1000] # This is to continue the effect of older thresholding after 2010\n",
    "\n",
    "data['IMPORT'] = data['FLUX'] % 2\n",
    "data['QUARTER'] = ((data['MONTH'] -1)// 3) + 1\n",
    "\n",
    "CN_full = pd.read_csv('./../../data/CN_full.csv', encoding = 'utf-8')\n",
    "data = data.merge(CN_full[['CN ID 8', 'CN ID 4']])#.persist()\n",
    "\n",
    "# Compute and save\n",
    "sourcing_strategies_qr = data.loc[data.IMPORT == 1].groupby(['YEAR', 'QUARTER','ID', 'CN ID 4', 'PYOD'])[['VART']].sum() #rm QUARTER for yearly dataset\n",
    "with ProgressBar():\n",
    "    out = sourcing_strategies_qr.compute()\n",
    "out.to_csv(save_path + 'sourcing_strategies_qr.csv')\n",
    "\n",
    "export_bundles_qr = data.loc[data.IMPORT == 0].groupby(['YEAR', 'QUARTER', 'ID', 'CN ID 4', 'PYOD', 'VAT'])[['VART']].sum()\n",
    "with ProgressBar():\n",
    "    out2 = export_bundles_qr.compute()\n",
    "out2.to_csv(save_path + 'export_bundles_qr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(save_path + 'sourcing_strategies_qr.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 15min 52.9s\n"
     ]
    }
   ],
   "source": [
    "columns = [u'YEAR', u'MONTH', u'FLUX', u'ID', u'CN ID 8', 'PYOD', u'VART']\n",
    "\n",
    "data = get_data(columns, drive_path, end_year = 2014)\n",
    "data = data.loc[data.VART >= 1000] # This is to continue the effect of older thresholding after 2010\n",
    "\n",
    "data['IMPORT'] = data['FLUX'] % 2\n",
    "\n",
    "CN_full = pd.read_csv('./../../data/CN_full.csv', encoding = 'utf-8')\n",
    "data = data.merge(CN_full[['CN ID 8', 'CN ID 4', 'CN label 4']])#.persist()\n",
    "\n",
    "# Compute and save\n",
    "sourcing_strategies = data.groupby(['IMPORT', 'YEAR', 'ID', 'CN ID 4', 'PYOD'])[['VART']].sum() #rm QUARTER for yearly dataset\n",
    "with ProgressBar():\n",
    "    out = sourcing_strategies.compute()\n",
    "out.to_csv(save_path + '_FCPY.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Basket of products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  2min 36.9s\n",
      "[                                        ] | 0% Completed |  6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miglesia/anaconda2/lib/python2.7/site-packages/dask/core.py:136: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  args2 = [_get_recursive(dsk, k, cache) for k in args]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5881fb91d292>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mProgressBar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0magg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0magg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_FYP.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/site-packages/dask/base.pyc\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[0mdask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \"\"\"\n\u001b[1;32m--> 156\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/site-packages/dask/base.pyc\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    393\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dask_keys__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m     \u001b[0mpostcomputes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/site-packages/dask/threaded.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(dsk, result, cache, num_workers, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m     results = get_async(pool.apply_async, len(pool._pool), dsk, result,\n\u001b[0;32m     74\u001b[0m                         \u001b[0mcache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_thread_get_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                         pack_exception=pack_exception, **kwargs)\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;31m# Cleanup pools associated to dead threads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/site-packages/dask/local.pyc\u001b[0m in \u001b[0;36mget_async\u001b[1;34m(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\u001b[0m\n\u001b[0;32m    490\u001b[0m             \u001b[1;31m# Main loop, wait on tasks to finish, insert new ones\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'waiting'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ready'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'running'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m                 \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfailed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m                     \u001b[0mexc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/site-packages/dask/local.pyc\u001b[0m in \u001b[0;36mqueue_get\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;31m# For more information see: https://bugs.python.org/issue1360\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m365\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m24\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m60\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'nt'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/Queue.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    175\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m             \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/miglesia/anaconda2/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    357\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m                     \u001b[0mdelay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelay\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m                     \u001b[0m_sleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgotit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Reusndant. these are already built for effective diversification.\n",
    "# columns = [u'YEAR', u'FLUX', u'ID', u'CN ID 8', 'CPA6', 'VART']\n",
    "\n",
    "# data = get_data(columns, drive_path, start_year = 2012, end_year = 2014)\n",
    "\n",
    "# data['IMPORT'] = data['FLUX'] % 2\n",
    "\n",
    "# CN_full = pd.read_csv('./../../data/CN_full.csv', encoding = 'utf-8')\n",
    "# data = data.merge(CN_full[['CN ID 8', 'CN ID 4']])#.persist()\n",
    "\n",
    "# # margins_info = data.groupby(['IMPORT','YEAR','ID']).agg({'VAT': tunique, 'PYOD': tunique, 'CN ID 4': tunique, 'VART': sum})\n",
    "\n",
    "# for col in ['CN ID 8', 'CN ID 4', 'CPA6']:\n",
    "#     agg = data.groupby(['ID','YEAR', 'IMPORT', col])[['VART']].sum().reset_index()\n",
    "\n",
    "#     with ProgressBar():\n",
    "#         agg = agg.compute()\n",
    "#     agg.to_csv(save_path + col.replace(' ', '_')+'_FYP.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Bernard's margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[######################################  ] | 97% Completed | 15min 10.3s"
     ]
    }
   ],
   "source": [
    "# It's failing for some reason\n",
    "\n",
    "# columns = [u'YEAR', u'FLUX', u'ID', u'VAT', 'CN ID 8', 'PYOD', u'VART']\n",
    "columns = [u'YEAR', u'FLUX', u'ID', u'CN ID 8', 'PYOD',  u'VAT', u'VART']\n",
    "\n",
    "data = get_data(columns, drive_path, end_year = 2014)\n",
    "data = data.loc[data.VART >= 1000] # This is to continue the effect of older thresholding after 2010\n",
    "\n",
    "\n",
    "data['IMPORT'] = data['FLUX'] % 2\n",
    "\n",
    "CN_full = pd.read_csv('./../data/CN_full.csv', encoding = 'utf-8')\n",
    "data = data.merge(CN_full[['CN ID 8', 'CN ID 4']])#.persist()\n",
    "\n",
    "# margins_info = data.groupby(['IMPORT','YEAR','ID']).agg({'VAT': tunique, 'PYOD': tunique, 'CN ID 4': tunique, 'VART': sum})\n",
    "data = data.loc[data.FLUX == 4].groupby(['IMPORT', 'YEAR', 'ID', 'VAT', 'CN ID 8'])['VART'].sum().reset_index()\n",
    "\n",
    "with ProgressBar():\n",
    "    out = data.compute()\n",
    "out.to_csv(save_path + 'bernards_margins_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.FLUX == 4].head()#.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Krammar's determinants of diversification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  3hr  1min 18.2s\n"
     ]
    }
   ],
   "source": [
    "columns = [u'YEAR', u'FLUX', u'ID', u'CN ID 8', u'PYOD', u'VAT', u'VART']\n",
    "\n",
    "data = get_data(columns, drive_path, end_year = 2014)\n",
    "data = data.loc[data.VART >= 1000] # This is to continue the effect of older thresholding after 2010\n",
    "\n",
    "data['IMPORT'] = data['FLUX'] % 2\n",
    "\n",
    "data = data.loc[data.FLUX == 4]\n",
    "\n",
    "grouped = data.groupby(['ID', 'YEAR', 'IMPORT'])\n",
    "\n",
    "with ProgressBar():\n",
    "    df = grouped.agg({'VART': 'sum','CN ID 8': tunique, u'PYOD': tunique, u'VAT': tunique}).compute()\n",
    "\n",
    "df.to_csv(save_path + 'dets_of_diversification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(save_path + 'dets_of_diversification.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Buyers and sellers by foreign country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[                                        ] | 0% Completed |  0.0s\r",
      "[                                        ] | 0% Completed |  0.1s\r",
      "[                                        ] | 0% Completed |  0.2s"
     ]
    }
   ],
   "source": [
    "columns = [u'YEAR', u'FLUX', u'ID', u'PYOD', u'VART']\n",
    "data = get_data(columns, drive_path, end_year = 2014)\n",
    "data = data.loc[data.VART >= 1000] # This is to continue the effect of older thresholding after 2010\n",
    "\n",
    "data['IMPORT'] = data['FLUX'] % 2\n",
    "\n",
    "data_by_dest = data.groupby(['IMPORT','YEAR','ID','PYOD'])['VART'].sum().reset_index()\n",
    "\n",
    "result = data_by_dest.groupby(['PYOD', 'YEAR']).agg({'ID': tunique, 'VART': 'sum'})\n",
    "\n",
    "with ProgressBar():\n",
    "    out = result.compute()\n",
    "    \n",
    "out.to_csv(save_path + 'destination.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Degree distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = 3\n",
    "# assortativity_res = []\n",
    "ID_degree_res = []\n",
    "VAT_degree_res = []\n",
    "\n",
    "for window in [1, 3]:\n",
    "    gap = (window-1)/2\n",
    "    center_years = arange(1997, 2014, 2)\n",
    "    print window\n",
    "\n",
    "    for Yc in center_years:\n",
    "        print Yc\n",
    "        data_sec = data.loc[data.YEAR - Yc <= gap]\n",
    "#         data_sec.groupby(['ID', 'VAT']).agg({'VART': sum })\n",
    "\n",
    "        data_sec_by_ID = data_sec.groupby(['ID']).agg({'VAT': tunique, 'VART': sum})\n",
    "\n",
    "        ID_degree = data_sec_by_ID[['VAT']].reset_index()\n",
    "        ID_degree.columns = [u'ID', u'ID_degree']\n",
    "        ID_degree['center_year'] = Yc\n",
    "        ID_degree['window'] = window\n",
    "        \n",
    "        with ProgressBar():\n",
    "            ID_deg = ID_degree.compute()\n",
    "            ID_deg['bin'] = pd.cut(log10(ID_deg['ID_degree']), bins = arange(-.49, 5.99, .25))\n",
    "            ID_deg.to_csv(save_path + 'ID_deg_'+str(Yc)+'_'+str(window)+'.csv', index = False)\n",
    "#         ID_degree_res += [ID_degree]     \n",
    "\n",
    "#         ID_deg = pd.read_csv()\n",
    "        sampling = ID_deg.groupby(['bin'], observed = True).apply(lambda x: x.sample(200, replace = True))\n",
    "\n",
    "        data_sec_sample = data_sec.loc[data_sec.ID.isin(sampling['ID'].values)]\n",
    "        data_sec_by_VAT = data_sec_sample.groupby(['VAT']).agg({'ID': tunique, 'VART': sum})\n",
    "\n",
    "        VAT_degree = data_sec_by_VAT[['ID']].reset_index()\n",
    "        VAT_degree.columns = [u'VAT', u'VAT_degree']\n",
    "        VAT_degree['center_year'] = Yc\n",
    "        VAT_degree['window'] = window\n",
    "        VAT_degree_res += [VAT_degree]\n",
    "        with ProgressBar():\n",
    "            VAT_deg = VAT_degree.compute()\n",
    "            VAT_deg.to_csv(save_path + 'VAT_deg_'+str(Yc)+'_'+str(window)+'.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(save_path + 'ID_deg_'+str(Yc)+'_'+str(window)).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1)\n",
    "# df_degrees.groupby('VAT_degree_bin')['ID_degree','VAT_degree'].quantile(.25).plot(x = 'VAT_degree', y = 'ID_degree', marker = '', ax = ax)\n",
    "# df_degrees.groupby('VAT_degree_bin')['ID_degree','VAT_degree'].quantile(.5).plot(x = 'VAT_degree', y = 'ID_degree', marker = '', ax = ax)\n",
    "# df_degrees.groupby('VAT_degree_bin')['ID_degree','VAT_degree'].quantile(.75).plot(x = 'VAT_degree', y = 'ID_degree', marker = '', ax = ax)\n",
    "\n",
    "# # df_degrees.groupby('ID_nunique_bin')['VAT_nunique','ID_nunique'].mean().plot(x = 'ID_nunique', y = 'VAT_nunique', marker = 'o', ax = ax)\n",
    "# df_degrees.groupby('ID_nunique')['VAT_nunique'].median().plot(x = 'index', y = 'VAT_nunique', marker = '.', linewidth = 0, ax = ax)\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Older stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links = pd.read_csv(save_path + 'buyer_seller_link_value.csv')\n",
    "# links['PERIOD'] = (links['YEAR'] - 1996) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degrees = links.groupby(['PERIOD', 'ID'])[['VAT']].nunique().rename(columns = {'VAT': 'ID_degree'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import log10, arange\n",
    "# degrees['log_ID_degree'] = log10(degrees['ID_degree'])\n",
    "# degrees['bin_ID_degree'] = pd.cut(degrees['log_ID_degree'], arange(-.25, 4.5, 0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree_dist = degrees.reset_index().groupby(['PERIOD', 'bin_ID_degree'])[['ID']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# fig, axs = plt.subplots(1, 2, figsize =(15, 6))\n",
    "\n",
    "# ax = axs[0]\n",
    "# for t in links['PERIOD'].unique():\n",
    "#     log10(degree_dist.loc[t]).reset_index().plot(marker = 'o', linewidth = 0, ax = ax, mec = 'None')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
