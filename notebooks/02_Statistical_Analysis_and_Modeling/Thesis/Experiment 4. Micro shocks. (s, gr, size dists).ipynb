{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries\n",
    "Import the necessary Python libraries for data manipulation, statistical analysis, and plotting. These include Pandas for data handling, Matplotlib for plotting, NumPy for numerical operations, and SciPy for statistical functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm, pareto\n",
    "from scipy.special import erf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation Functions\n",
    "Define functions to generate and manipulate distributions:\n",
    "- `get_clipped_lognormal`: Generates a clipped lognormal distribution.\n",
    "- `get_n`: Divides data into specified quantiles and counts the number of observations in each quantile.\n",
    "- `generate_pareto_samples`: Produces samples from a Pareto distribution and returns their logarithm.\n",
    "These functions are essential for simulating different economic data distributions used in the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_clipped_lognormal(mu, sigma, lower_bound, sample_size):\n",
    "    \"\"\"\n",
    "    Generate a sample of lognormal distribution clipped at a lower bound.\n",
    "\n",
    "    :param mu: Mean of the lognormal distribution\n",
    "    :param sigma: Standard deviation of the lognormal distribution\n",
    "    :param lower_bound: The threshold to clip the distribution\n",
    "    :param sample_size: The desired size of the sample\n",
    "    :return: Array of samples from the clipped lognormal distribution\n",
    "    \"\"\"\n",
    "    # Calculate the cumulative threshold to adjust the sample size\n",
    "    z = (mu - lower_bound) / sigma\n",
    "    cumulative_threshold = 1 - .5 * (1 + erf(z / np.sqrt(2)))\n",
    "\n",
    "    # Adjust sample size to account for the clipping\n",
    "    adjusted_sample_size = int(round(sample_size / (1 - cumulative_threshold)))\n",
    "    samples = np.random.normal(mu, sigma, adjusted_sample_size)\n",
    "\n",
    "    # Clip the distribution and return the required number of samples\n",
    "    clipped_samples = np.sort(samples)[-sample_size:]\n",
    "    return clipped_samples\n",
    "\n",
    "\n",
    "def get_n(x, num_quantiles):\n",
    "    \"\"\"\n",
    "    Divide the array x into num_quantiles quantiles and return the bins and counts in each bin.\n",
    "\n",
    "    :param x: Array of values to be divided into quantiles.\n",
    "    :param num_quantiles: Number of quantiles to divide x into.\n",
    "    :return: Tuple (bins, counts) where bins is the Series of quantile bins and counts is the array of counts in each bin.\n",
    "    \"\"\"\n",
    "    cumulative_sum = np.cumsum(np.power(10, x))\n",
    "    bins = pd.cut(pd.Series(cumulative_sum), num_quantiles)\n",
    "    counts = bins.value_counts().values\n",
    "    return bins, counts\n",
    "\n",
    "def generate_pareto_samples(n, shape_param, scale_param):\n",
    "    \"\"\"\n",
    "    Generate Pareto-distributed samples and return their logarithm.\n",
    "\n",
    "    :param n: Number of samples to generate.\n",
    "    :param shape_param: Shape parameter (b) for the Pareto distribution.\n",
    "    :param scale_param: Scale parameter (scale) for the Pareto distribution.\n",
    "    :return: Array of log-transformed Pareto samples.\n",
    "    \"\"\"\n",
    "    pareto_samples = pareto.rvs(b=-shape_param, size=n, scale=10**scale_param) + 1\n",
    "    return np.log10(pareto_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up Distribution Parameters and Generating Data\n",
    "- Define parameters for a lognormal distribution (`sigma`, `mu`) and a clipping threshold (`lower_bound`).\n",
    "- Generate a sample of a lognormal distribution clipped at `lower_bound`.\n",
    "- Use the `get_n` function to divide this distribution into quantiles and calculate the counts in each quantile.\n",
    "- Prepare for generating a Pareto distribution by setting its parameters (`z_0`, `value_qs_1`).\n",
    "- Generate Pareto distribution samples and store them for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameters for the clipped lognormal distribution\n",
    "sigma = 1.2810\n",
    "mu = 4.53690\n",
    "lower_bound = 3.0\n",
    "sample_size = int(1e5)\n",
    "\n",
    "# Generating the clipped lognormal distribution\n",
    "x_logn_clip3 = get_clipped_lognormal(mu, sigma, lower_bound, sample_size)\n",
    "\n",
    "# Quantiles for the clipped lognormal distribution\n",
    "bins, partition_ns = get_n(x_logn_clip3, 10)\n",
    "N_tail = partition_ns[1:].sum()\n",
    "\n",
    "# Generate samples for the clipped lognormal distribution with 90% tail\n",
    "x_logn_clip3_90 = x_logn_clip3[-N_tail:]\n",
    "\n",
    "# Parameters for the Pareto distribution\n",
    "z_0 = -1.10420\n",
    "value_qs_1 = 6.67465\n",
    "norm_factor = 1.375\n",
    "\n",
    "# Generating Pareto distribution samples\n",
    "x_pareto = generate_pareto_samples(N_tail, z_0, value_qs_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing and Storing Experiment Results\n",
    "- Convert the accumulated results from the experiments into a Pandas DataFrame for easier analysis and visualization.\n",
    "- The DataFrame `experiment_data` contains detailed results for each experiment iteration, including distribution type, size distribution, shock intensity, and calculated metrics.\n",
    "- Print a completion message to signify the end of the experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Experiment parameters\n",
    "ss = np.arange(0.1, 0.8, 0.2)\n",
    "num_repetitions = 100\n",
    "num_years = 17\n",
    "num_quantiles = 10\n",
    "distributions = ['norm', 'lapl']\n",
    "size_distributions = [x_logn_clip3, x_logn_clip3_90, x_pareto]\n",
    "size_dist_names = ['Logn', 'Logn90', 'Pareto']\n",
    "\n",
    "# Prepare for results\n",
    "experiment_results = []\n",
    "\n",
    "# Run experiments for each distribution and size distribution\n",
    "for dist in distributions:\n",
    "    for size_dist_index, size_dist in enumerate(size_distributions):\n",
    "        print('Running experiments for', size_dist_names[size_dist_index])\n",
    "        bins, partition_counts = get_n(size_dist, num_quantiles)\n",
    "        for quantile_index, quantile in enumerate(bins.unique()):\n",
    "            firm_sizes = pd.Series(size_dist).loc[bins == quantile].values\n",
    "            num_firms = partition_counts[quantile_index]\n",
    "            for s in ss:\n",
    "                for repetition in range(num_repetitions):\n",
    "                    # Generate shocks based on distribution\n",
    "                    if dist == 'norm':\n",
    "                        shocks = np.random.normal(0, s, (num_firms, num_years))\n",
    "                    elif dist == 'lapl':\n",
    "                        shocks = np.random.laplace(0, s/np.sqrt(2), (num_firms, num_years))\n",
    "\n",
    "                    # Calculate log of aggregated ratios\n",
    "                    aggregated_ratios = np.log10(np.power(10, firm_sizes[:, None] + shocks).sum(0) /\n",
    "                                                 np.power(10, firm_sizes[:, None]).sum(0))\n",
    "\n",
    "                    # Store results\n",
    "                    experiment_results.append([dist, size_dist_names[size_dist_index], s, num_firms, \n",
    "                                               repetition, aggregated_ratios.mean(), aggregated_ratios.std()])\n",
    "\n",
    "# Convert results to DataFrame\n",
    "experiment_data = pd.DataFrame(experiment_results, \n",
    "                               columns=['Distribution', 'Size_Dist', 'Shock_Intensity', \n",
    "                                        'Num_Firms', 'Repetition', 'Mean_Aggregated_Ratio', 'Std_Aggregated_Ratio'])\n",
    "\n",
    "print(\"Experiments completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
