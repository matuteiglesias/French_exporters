{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Microshocks and Macro Variability: A Detailed Exploration\n",
    "\n",
    "**Background**\n",
    "\n",
    "In the complex dynamics of economic systems, the study of micro-level shocks and their macro-level implications is crucial. Firms or economic agents often experience microshocks â€” small, individual-level disturbances that can arise from a multitude of sources like market changes, technological innovations, or regulatory shifts. Understanding how these microshocks aggregate and manifest at a macro level, such as impacting an entire sector's volatility, is vital for economic forecasting, policy-making, and risk management.\n",
    "\n",
    "**Microshocks and Their Aggregation**\n",
    "\n",
    "Microshocks, in this context, refer to deviations in firm-level sales from their average values. These deviations can be modeled using different distributions, each reflecting a unique aspect of real-world phenomena. For instance, Gaussian (normal) distributions are used for their simplicity and symmetry, representing common, everyday fluctuations. Laplace distributions, with their sharper peaks and heavier tails, might signify more extreme yet equally probable positive and negative shocks. Empirical distributions, derived from actual data, provide the most realistic representation, incorporating the actual observed variability in the data.\n",
    "\n",
    "The aggregation of these microshocks gives insight into how individual firm-level variances accumulate to create sectoral or market-level volatility. This aggregation is not merely a sum of individual variances but a complex interaction that can lead to amplification or dampening of overall volatility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **Introduction and Setup**\n",
    "   - Import necessary libraries and set display options.\n",
    "   - A brief description of the notebook's purpose and the data being analyzed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_680790/106602846.py:6: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. **Data Loading and Initial Exploration**\n",
    "   - Load the dataset and provide a brief overview.\n",
    "   - Initial exploration and preprocessing of the data.\n",
    "   - Generate summary statistics to understand the dataset better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions: (3745743, 5)\n",
      "Column names: ['ID', 'IMPORT', 'YEAR', 'VART', 'VFTE']\n",
      "First few rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>IMPORT</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>VART</th>\n",
       "      <th>VFTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1997</td>\n",
       "      <td>39221936</td>\n",
       "      <td>9663564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>45264143</td>\n",
       "      <td>17060750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>1997</td>\n",
       "      <td>656617</td>\n",
       "      <td>656593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>335002</td>\n",
       "      <td>335387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>330</td>\n",
       "      <td>0</td>\n",
       "      <td>1997</td>\n",
       "      <td>23402</td>\n",
       "      <td>23402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  IMPORT  YEAR      VART      VFTE\n",
       "0    0       0  1997  39221936   9663564\n",
       "1    0       1  1997  45264143  17060750\n",
       "2  215       0  1997    656617    656593\n",
       "3  223       1  1997    335002    335387\n",
       "4  330       0  1997     23402     23402"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics of Sales Data:\n",
      "YEAR           1997          1998          1999          2000          2001  \\\n",
      "count  1.092510e+05  1.121870e+05  1.136910e+05  1.154570e+05  1.144670e+05   \n",
      "mean   2.317227e+06  2.403965e+06  2.464215e+06  2.794554e+06  2.864126e+06   \n",
      "std    5.027168e+07  5.550315e+07  5.787878e+07  6.421588e+07  6.530466e+07   \n",
      "min    1.000000e+03  1.000000e+03  1.000000e+03  1.000000e+03  1.000000e+03   \n",
      "25%    6.857500e+03  6.860000e+03  6.893500e+03  7.104000e+03  7.035000e+03   \n",
      "50%    3.787400e+04  3.864700e+04  3.814900e+04  4.014400e+04  4.009400e+04   \n",
      "75%    2.514745e+05  2.606820e+05  2.614915e+05  2.777180e+05  2.951255e+05   \n",
      "max    1.072210e+10  1.340463e+10  1.421550e+10  1.514020e+10  1.440674e+10   \n",
      "\n",
      "YEAR           2002          2003          2004          2005          2006  \\\n",
      "count  1.141060e+05  1.115990e+05  1.097970e+05  1.087200e+05  1.077490e+05   \n",
      "mean   2.850487e+06  2.856554e+06  3.048637e+06  3.264325e+06  3.608280e+06   \n",
      "std    6.194888e+07  6.408995e+07  6.440150e+07  7.293776e+07  8.213797e+07   \n",
      "min    1.000000e+03  1.000000e+03  1.000000e+03  1.000000e+03  1.000000e+03   \n",
      "25%    7.100000e+03  7.060000e+03  7.100000e+03  7.305750e+03  7.436000e+03   \n",
      "50%    3.965950e+04  3.893300e+04  3.929300e+04  4.113600e+04  4.227900e+04   \n",
      "75%    2.983022e+05  2.960195e+05  3.111160e+05  3.238622e+05  3.448040e+05   \n",
      "max    1.352745e+10  1.424412e+10  1.344459e+10  1.321503e+10  1.376589e+10   \n",
      "\n",
      "YEAR           2007          2008          2009          2010          2011  \\\n",
      "count  1.065200e+05  1.039410e+05  1.001110e+05  9.627400e+04  8.886600e+04   \n",
      "mean   3.749065e+06  3.957725e+06  3.395151e+06  4.027692e+06  4.711226e+06   \n",
      "std    8.272569e+07  8.368816e+07  7.274193e+07  8.998755e+07  9.779443e+07   \n",
      "min    1.000000e+03  1.000000e+03  1.000000e+03  1.000000e+03  1.000000e+03   \n",
      "25%    7.711750e+03  7.835000e+03  7.500000e+03  8.234500e+03  7.850000e+03   \n",
      "50%    4.521550e+04  4.589900e+04  4.247700e+04  4.899250e+04  4.262350e+04   \n",
      "75%    3.693692e+05  3.801850e+05  3.406545e+05  4.006465e+05  4.476902e+05   \n",
      "max    1.448312e+10  1.489217e+10  1.426084e+10  1.642449e+10  1.698499e+10   \n",
      "\n",
      "YEAR           2012          2013  \n",
      "count  9.083100e+04  9.079600e+04  \n",
      "mean   4.758422e+06  4.688684e+06  \n",
      "std    1.034295e+08  1.046296e+08  \n",
      "min    1.000000e+03  1.000000e+03  \n",
      "25%    7.636500e+03  7.618750e+03  \n",
      "50%    4.027300e+04  4.080200e+04  \n",
      "75%    4.469500e+05  4.431962e+05  \n",
      "max    2.032925e+10  2.098978e+10  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./../../../data/processed/ID_Y.csv')\n",
    "# df = pd.read_csv('./../../data/processed/.csv')  # Alternative path, if needed\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset dimensions:\", df.shape)\n",
    "print(\"Column names:\", df.columns.tolist())\n",
    "print(\"First few rows of the dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "# Filtering data where IMPORT is equal to Mbool (0) and summarizing sales\n",
    "Mbool = 0\n",
    "sales = df.loc[df.IMPORT == Mbool].groupby(['ID', 'YEAR'])['VART'].sum().unstack()\n",
    "\n",
    "# Sorting the sales data\n",
    "sales = sales.loc[sales.sum(1).sort_values().index]\n",
    "\n",
    "# Summary statistics of the sales data\n",
    "sales_summary = sales.describe()\n",
    "print(\"Summary Statistics of Sales Data:\")\n",
    "print(sales_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. **Sales Data Analysis**\n",
    "   - Detailed analysis of sales data.\n",
    "   - Calculation of logarithmic sales and their distribution.\n",
    "   - Examination of sales size and partitioning into quantiles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the logarithm of sales\n",
    "logsales = np.log10(sales)\n",
    "\n",
    "# Detrending the logarithmic sales by subtracting the mean\n",
    "demlogsales = logsales.subtract(logsales.mean(1), axis=0)\n",
    "# Calculating total sales size\n",
    "sizes = sales.loc[sales.sum(1).sort_values().index].sum(1)\n",
    "\n",
    "# Partitioning sales into quantiles\n",
    "Q = 10  # Number of quantiles\n",
    "parts = pd.cut(sizes.cumsum()/sizes.sum(), Q, labels=range(Q))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "4. **Effective Quantile Analysis**\n",
    "   - Compute and analyze the effective number of quantiles.\n",
    "   - Explore how sales data is distributed across these quantiles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective number of data points in each quantile:\n",
      "0    98643\n",
      "1     4212\n",
      "2     1414\n",
      "3      635\n",
      "4      319\n",
      "5      168\n",
      "6       92\n",
      "7       46\n",
      "8       17\n",
      "9        5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculating the effective number of data points in each quantile\n",
    "eff_nq = sales.groupby(parts).count().mean(1).round().astype(int)\n",
    "print(\"Effective number of data points in each quantile:\")\n",
    "print(eff_nq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Microshock Analysis**\n",
    "   - Analyze the standard deviation within parts.\n",
    "   - Discuss microshocks in the context of the data and their implications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Microshocks\n",
    "demlogsales['parts'] = parts\n",
    "# Filter to keep only those entries with more than one observation per ID\n",
    "std_data = demlogsales.loc[demlogsales.iloc[:, :-1].count(1) > 2]\n",
    "\n",
    "# Reshaping data for standard deviation analysis\n",
    "std_info = std_data.reset_index().set_index(['ID', 'parts']).stack()\n",
    "# Standard deviation by quantile\n",
    "std_q = std_info.groupby(level='parts').std()\n",
    "# Average standard deviation across quantiles\n",
    "avg_std = std_info.std()\n",
    "\n",
    "# Displaying the results\n",
    "print(\"Average standard deviation across quantiles:\", avg_std)\n",
    "display(std_q)\n",
    "\n",
    "# emp_nqs = np.round(nq.sort_values()).astype(int)\n",
    "\n",
    "# Extracting empirical shocks\n",
    "emp_shocks = std_info.values\n",
    "\n",
    "# Average value of empirical shocks\n",
    "print(\"Average of empirical shocks:\", emp_shocks.mean())\n",
    "\n",
    "# I don't knwo the possible mus, because on every firm I subtracted the observed mean value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Experiment**\n",
    "\n",
    "The experiment conducted through the code aims to simulate and analyze these phenomena. We create synthetic microshocks for a set of firms over time, using different distributions (Gaussian, Laplace, Empirical). These shocks are then aggregated to observe the resulting macro-level variance.\n",
    "\n",
    "**Key Components of the Experiment**\n",
    "\n",
    "1. **Generation of Microshocks**: Microshocks are generated for each firm in the dataset, varying in intensity and distribution. The parameters 'mu' (mean) and 'sigma' (standard deviation) are varied to simulate different scenarios. The 'empirical' shocks are drawn from actual data to mimic real-world conditions closely.\n",
    "\n",
    "2. **Aggregation Process**: The microshocks are aggregated to understand their cumulative effect. This step is crucial as it mimics the real-world scenario where individual firm-level disturbances contribute to the overall sectoral or market volatility.\n",
    "\n",
    "3. **Analysis of Macro Variability**: The aggregated results are analyzed in terms of mean, standard deviation, and variance. These metrics provide insights into the overall impact of microshocks on the macro economy. The log ratios help in understanding the multiplicative effect of these shocks.\n",
    "\n",
    "**Purpose of Precision and Specificity**\n",
    "\n",
    "Being precise and specific in this study allows for a nuanced understanding of economic dynamics. It helps in:\n",
    "\n",
    "- **Identifying the Impact of Different Shock Types**: By comparing different distributions, we can understand which types of shocks (common vs. extreme) have more significant impacts on the macro economy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Parameter Setup for Experiments**\n",
    "   - Define and explain the parameters used in the experiments (e.g., `mus`, `ss`, `M`, `T`).\n",
    "   - Discuss the rationale behind these parameter choices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_shocks(distribution, mu, sigma, n, T, emp_shocks=None):\n",
    "    if distribution == 'norm':\n",
    "        return np.random.normal(mu, sigma, (n, T))\n",
    "    elif distribution == 'lapl':\n",
    "        return np.random.laplace(mu, sigma / np.sqrt(2), (n, T))\n",
    "    elif distribution == 'emp':\n",
    "        s0 = emp_shocks.std()\n",
    "        return (mu + np.random.choice(emp_shocks, n * T) * (sigma / s0)).reshape(n, T)\n",
    "\n",
    "def calculate_ratios(shocks, n):\n",
    "    ratio = np.power(10, shocks).sum(0) / n\n",
    "    log_ratio = np.log10(ratio)\n",
    "    return ratio.mean(), ratio.std(), ratio.var(), log_ratio.mean(), log_ratio.std(), log_ratio.var()\n",
    "\n",
    "# Parameters\n",
    "Q = 10\n",
    "# Analysis parameters\n",
    "partition = eff_nq.astype(int)\n",
    "ss = np.arange(0.1, 0.8, 0.1)  # Range of shock scales\n",
    "M = 200  # Number of simulations\n",
    "T = 17   # Time periods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "7. **Experimentation with Different Distributions**\n",
    "   - Conduct experiments with different distributions (Gaussian, Laplace, empirical).\n",
    "   - Explore the impact of these distributions on the results.\n",
    "\n",
    "8. **Result Compilation and Export**\n",
    "   - Compile the results from the experiments into a DataFrame.\n",
    "   - Export the results to a CSV file for further analysis or reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 1, N: 4212\n",
      "Quantile: 2, N: 1414\n",
      "Quantile: 3, N: 635\n",
      "Quantile: 4, N: 319\n",
      "Quantile: 5, N: 168\n",
      "Quantile: 6, N: 92\n",
      "Quantile: 7, N: 46\n",
      "Quantile: 8, N: 17\n",
      "Quantile: 9, N: 5\n",
      "Quantile: 1, N: 4212\n",
      "Quantile: 2, N: 1414\n",
      "Quantile: 3, N: 635\n",
      "Quantile: 4, N: 319\n",
      "Quantile: 5, N: 168\n",
      "Quantile: 6, N: 92\n",
      "Quantile: 7, N: 46\n",
      "Quantile: 8, N: 17\n",
      "Quantile: 9, N: 5\n",
      "Quantile: 1, N: 4212\n",
      "Quantile: 2, N: 1414\n",
      "Quantile: 3, N: 635\n",
      "Quantile: 4, N: 319\n",
      "Quantile: 5, N: 168\n",
      "Quantile: 6, N: 92\n",
      "Quantile: 7, N: 46\n",
      "Quantile: 8, N: 17\n",
      "Quantile: 9, N: 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = []\n",
    "for dist in ['norm', 'lapl', 'emp']:\n",
    "    print(f\"Distribution: {dist}\")\n",
    "    for q, n in enumerate(partition.values[1:], start=1):\n",
    "        print(f\"Quantile: {q}, N: {n}\")\n",
    "        for s in ss:\n",
    "            for mu in mus:\n",
    "                for m in range(M):\n",
    "                    shocks = generate_shocks(dist, mu, s, n, T, emp_shocks=emp_shocks if dist == 'emp' else None)\n",
    "                    mean_ratio, std_ratio, var_ratio, mean_log_ratio, std_log_ratio, var_log_ratio = calculate_ratios(shocks, n)\n",
    "                    results.append([dist, s, mu, n, m, mean_ratio, std_ratio, var_ratio, mean_log_ratio, std_log_ratio, var_log_ratio])\n",
    "\n",
    "result_df = pd.DataFrame(results, columns=['dist', 's', 'mu', 'nq', 'repeat', 'mean_ratio', 'std_ratio', 'var_ratio', 'mean_log_ratio', 'std_log_ratio', 'var_log_ratio'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('./../../../data/processed/microshocks.csv', index=False)\n",
    "# result.to_csv('./experiment_3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist</th>\n",
       "      <th>s</th>\n",
       "      <th>mu</th>\n",
       "      <th>nq</th>\n",
       "      <th>repeat</th>\n",
       "      <th>mean_ratio</th>\n",
       "      <th>std_ratio</th>\n",
       "      <th>var_ratio</th>\n",
       "      <th>mean_log_ratio</th>\n",
       "      <th>std_log_ratio</th>\n",
       "      <th>var_log_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>norm</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4212</td>\n",
       "      <td>0</td>\n",
       "      <td>1.026879</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.011515</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>norm</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4212</td>\n",
       "      <td>1</td>\n",
       "      <td>1.026152</td>\n",
       "      <td>0.003554</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.011209</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>norm</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4212</td>\n",
       "      <td>2</td>\n",
       "      <td>1.027322</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.011702</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>norm</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4212</td>\n",
       "      <td>3</td>\n",
       "      <td>1.026874</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.011515</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>norm</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4212</td>\n",
       "      <td>4</td>\n",
       "      <td>1.027669</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.011851</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dist    s   mu    nq  repeat  mean_ratio  std_ratio  var_ratio  \\\n",
       "0  norm  0.1  0.0  4212       0    1.026879   0.004687   0.000022   \n",
       "1  norm  0.1  0.0  4212       1    1.026152   0.003554   0.000013   \n",
       "2  norm  0.1  0.0  4212       2    1.027322   0.004640   0.000022   \n",
       "3  norm  0.1  0.0  4212       3    1.026874   0.003201   0.000010   \n",
       "4  norm  0.1  0.0  4212       4    1.027669   0.003650   0.000013   \n",
       "\n",
       "   mean_log_ratio  std_log_ratio  var_log_ratio  \n",
       "0        0.011515       0.001982       0.000004  \n",
       "1        0.011209       0.001506       0.000002  \n",
       "2        0.011702       0.001960       0.000004  \n",
       "3        0.011515       0.001354       0.000002  \n",
       "4        0.011851       0.001542       0.000002  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist</th>\n",
       "      <th>s</th>\n",
       "      <th>mu</th>\n",
       "      <th>nq</th>\n",
       "      <th>repeat</th>\n",
       "      <th>mean_ratio</th>\n",
       "      <th>std_ratio</th>\n",
       "      <th>var_ratio</th>\n",
       "      <th>mean_log_ratio</th>\n",
       "      <th>std_log_ratio</th>\n",
       "      <th>var_log_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188995</th>\n",
       "      <td>emp</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>195</td>\n",
       "      <td>3.817261</td>\n",
       "      <td>3.622178</td>\n",
       "      <td>13.120174</td>\n",
       "      <td>0.419501</td>\n",
       "      <td>0.363732</td>\n",
       "      <td>0.132301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188996</th>\n",
       "      <td>emp</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>3.252686</td>\n",
       "      <td>1.971284</td>\n",
       "      <td>3.885962</td>\n",
       "      <td>0.417249</td>\n",
       "      <td>0.307898</td>\n",
       "      <td>0.094801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188997</th>\n",
       "      <td>emp</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>2.271387</td>\n",
       "      <td>1.444192</td>\n",
       "      <td>2.085690</td>\n",
       "      <td>0.272243</td>\n",
       "      <td>0.272949</td>\n",
       "      <td>0.074501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188998</th>\n",
       "      <td>emp</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>198</td>\n",
       "      <td>2.403494</td>\n",
       "      <td>2.003725</td>\n",
       "      <td>4.014913</td>\n",
       "      <td>0.292215</td>\n",
       "      <td>0.253133</td>\n",
       "      <td>0.064076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188999</th>\n",
       "      <td>emp</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>199</td>\n",
       "      <td>5.959136</td>\n",
       "      <td>8.887765</td>\n",
       "      <td>78.992362</td>\n",
       "      <td>0.495335</td>\n",
       "      <td>0.433848</td>\n",
       "      <td>0.188224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dist    s   mu  nq  repeat  mean_ratio  std_ratio  var_ratio  \\\n",
       "188995  emp  0.7  0.1   5     195    3.817261   3.622178  13.120174   \n",
       "188996  emp  0.7  0.1   5     196    3.252686   1.971284   3.885962   \n",
       "188997  emp  0.7  0.1   5     197    2.271387   1.444192   2.085690   \n",
       "188998  emp  0.7  0.1   5     198    2.403494   2.003725   4.014913   \n",
       "188999  emp  0.7  0.1   5     199    5.959136   8.887765  78.992362   \n",
       "\n",
       "        mean_log_ratio  std_log_ratio  var_log_ratio  \n",
       "188995        0.419501       0.363732       0.132301  \n",
       "188996        0.417249       0.307898       0.094801  \n",
       "188997        0.272243       0.272949       0.074501  \n",
       "188998        0.292215       0.253133       0.064076  \n",
       "188999        0.495335       0.433848       0.188224  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
