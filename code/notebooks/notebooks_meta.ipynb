{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nbformat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nbformat\n",
    "\n",
    "def extract_notebook_content(notebook_path):\n",
    "    \"\"\"\n",
    "    Extracts content from a Jupyter notebook.\n",
    "    For this example, we are extracting all markdown cells and code comments.\n",
    "    \"\"\"\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as file:\n",
    "        notebook = nbformat.read(file, as_version=4)\n",
    "        content = []\n",
    "\n",
    "        for cell in notebook.cells:\n",
    "            if cell.cell_type == 'markdown':\n",
    "                content.append(cell.source)\n",
    "            elif cell.cell_type == 'code':\n",
    "                # Extracting comments from code cells\n",
    "                comments = [line for line in cell.source.split('\\n') if line.strip().startswith('#')]\n",
    "                content.extend(comments)\n",
    "\n",
    "        return '\\n'.join(content)\n",
    "\n",
    "project_directory = './../../code/notebooks/'  # Replace with the path to your project directory\n",
    "notebooks_content = {}\n",
    "\n",
    "for file in os.listdir(project_directory):\n",
    "    if file.endswith('.ipynb'):\n",
    "        notebook_path = os.path.join(project_directory, file)\n",
    "        notebooks_content[file] = extract_notebook_content(notebook_path)\n",
    "\n",
    "# At this point, 'notebooks_content' contains the extracted content from each notebook\n",
    "# You can now proceed to analyze this content as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prompt_text = \"\"\"\n",
    "Hello, I have a series of Jupyter notebooks as part of a data analysis project on French exporters. I need an in-depth and technically detailed analysis of this notebook to understand its role in the overall project. For this notebook, please provide the following information with specific examples and critical evaluation:\n",
    "\n",
    "    Main Objective and Scope:\n",
    "        - What is the primary focus or research question addressed in this notebook?\n",
    "        - Identify the specific dataset(s) or data types analyzed. Please provide details on the nature and structure of these datasets.\n",
    "\n",
    "    Methodological Approach:\n",
    "        - Give a detailed overview of the analytical methods, algorithms, or models used. How do these approaches specifically apply to the data and objectives?\n",
    "        - Describe in detail the data processing and analysis techniques applied. Are these techniques standard in the field, or are they novel or unconventional?\n",
    "\n",
    "    Key Findings or Results:\n",
    "        - Summarize the significant results, insights, or conclusions derived from the analysis. Please include specific examples or excerpts from the notebook.\n",
    "        - Discuss any visualizations or charts used. How do they contribute to illustrating the findings? Are they effectively designed?\n",
    "\n",
    "    Areas for Improvement or Updates:\n",
    "        - Critically evaluate areas where this notebook could be updated or improved. Are there outdated methods, lack of comments, or inefficient code segments?\n",
    "        - Recommend specific additional analyses or data that could enhance the notebook's value. How would these changes impact the overall findings?\n",
    "\n",
    "    Potential Integrations or Relationships:\n",
    "        - Suggest how this notebook could be integrated with or related to other notebooks in the project. Are there overlapping or complementary aspects?\n",
    "        - Identify potential gaps in the current analysis that might be filled by other analyses or data sources.\n",
    "\n",
    "    General Observations:\n",
    "        - Provide any additional observations or notes that could be relevant for restructuring the project. Highlight format inconsistencies, missing data, or areas lacking in clarity.\n",
    "\n",
    "    Code Analysis (if applicable):\n",
    "        - Provide a detailed review of the code quality, efficiency, and potential areas for optimization or refactoring.\n",
    "\n",
    "Please structure your response with clear headings for each section and be as detailed and technical as possible. \n",
    "\n",
    "Notebook Content: {}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \"\"\"\n",
    "Hello, I have a series of Jupyter notebooks as part of a data analysis project on French exporters. I need an in-depth and technically detailed analysis of this notebook to understand its role in the overall project. For this notebook, please provide the following information with specific examples and critical evaluation:\n",
    "\n",
    "    Main Objective and Scope:\n",
    "        - What is the primary focus or research question addressed in this notebook?\n",
    "        - Identify the specific dataset(s) or data types analyzed. Please provide details on the nature and structure of these datasets.\n",
    "\n",
    "    Methodological Approach:\n",
    "        - Give a detailed overview of the analytical methods, algorithms, or models used. How do these approaches specifically apply to the data and objectives?\n",
    "        - Describe in detail the data processing and analysis techniques applied. Are these techniques standard in the field, or are they novel or unconventional?\n",
    "\n",
    "    Key Findings or Results:\n",
    "        - Summarize the significant results, insights, or conclusions derived from the analysis. Please include specific examples or excerpts from the notebook.\n",
    "        - Discuss any visualizations or charts used. How do they contribute to illustrating the findings? Are they effectively designed?\n",
    "\n",
    "    Areas for Improvement or Updates:\n",
    "        - Critically evaluate areas where this notebook could be updated or improved. Are there outdated methods, lack of comments, or inefficient code segments?\n",
    "        - Recommend specific additional analyses or data that could enhance the notebook's value. How would these changes impact the overall findings?\n",
    "\n",
    "    Potential Integrations or Relationships:\n",
    "        - Suggest how this notebook could be integrated with or related to other notebooks in the project. Are there overlapping or complementary aspects?\n",
    "        - Identify potential gaps in the current analysis that might be filled by other analyses or data sources.\n",
    "\n",
    "    General Observations:\n",
    "        - Provide any additional observations or notes that could be relevant for restructuring the project. Highlight format inconsistencies, missing data, or areas lacking in clarity.\n",
    "\n",
    "    Code Analysis (if applicable):\n",
    "        - Provide a detailed review of the code quality, efficiency, and potential areas for optimization or refactoring.\n",
    "\n",
    "Please structure your response with clear headings for each section and be as detailed and technical as possible. \n",
    "\n",
    "Notebook Content: {}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \"\"\"\n",
    "Please provide a condensed technical summary of the following Jupyter notebook. \n",
    "Focus on highlighting key computational and scientific aspects, including specific Python packages, statistical methods, mathematical models, and thematic elements related to economics or other relevant fields. \n",
    "Aim for a balance between brevity and technical detail, summarizing the notebook's purpose in one sentence, followed by a list of technical keywords and concepts. Limit your response to 100 words.\n",
    "\n",
    "Notebook Content: {}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \"\"\"\n",
    "Hello, I have a series of Jupyter notebooks as part of a data analysis project on French exporters. I require a detailed, code-centric analysis of this notebook to better integrate and optimize the overall project. For this notebook, please provide the following detailed technical evaluation:\n",
    "\n",
    "1. **Code Breakdown and Functionality:**\n",
    "   - Examine each code cell and explain its functionality. How does each segment of code contribute to the notebook's objectives?\n",
    "   - Identify dependencies between code cells. Are there cells that must be executed in a specific sequence? Highlight any interdependencies.\n",
    "\n",
    "2. **Data Handling and Processing:**\n",
    "   - Detail the methods used for data handling and processing. What specific libraries or tools are employed, and how are they used to manipulate the data?\n",
    "   - Discuss the efficiency and scalability of the data processing methods. Are there opportunities for optimization?\n",
    "\n",
    "3. **Analytical Techniques and Modeling:**\n",
    "   - Elaborate on the analytical methods, algorithms, or models used. How are they implemented in the code, and how do they address the research questions?\n",
    "   - Evaluate the appropriateness and effectiveness of the applied techniques. Suggest alternatives or improvements if necessary.\n",
    "\n",
    "4. **Visualization and Results Presentation:**\n",
    "   - Assess the visualizations and results presentation. How are the findings communicated through charts or tables in the notebook?\n",
    "   - Provide suggestions for enhancing the clarity and impact of these visual elements.\n",
    "\n",
    "5. **Refactoring and Modularization:**\n",
    "   - Critique the current structure of the notebook. Identify opportunities for refactoring and modularization.\n",
    "   - Suggest functions or classes that can be extracted for better code reusability and readability.\n",
    "\n",
    "6. **Integration with Other Notebooks:**\n",
    "   - Propose ways this notebook could be integrated with other notebooks in the project. Are there shared functions or data that can be centralized?\n",
    "   - Recommend strategies for streamlining the overall project structure through consolidation or separation of notebook content.\n",
    "\n",
    "7. **Gap Analysis and Further Exploration:**\n",
    "   - Point out any gaps in the analysis or areas that warrant further exploration.\n",
    "   - How might additional data or alternative approaches enrich the existing analysis?\n",
    "\n",
    "Please structure your response with detailed explanations and specific references to the notebook content. \n",
    "\n",
    "Notebook Content: {}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \"\"\"\n",
    "Summarize the main purpose, methodologies, analysis methods used, and key themes of this Jupyter notebook. \n",
    "Focus on critical functions, data analysis techniques, and specific subject areas. \n",
    "Highlight essential functions and any specialized techniques or topics covered. \n",
    "Provide a concise two to three-line summary. Limit the summary to two to three lines.\n",
    "Notebook Content: {}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Distribution of growth rates (=random).ipynb',\n",
       " 'Gabaix numerical tests.ipynb',\n",
       " 'Quantile Simulations.ipynb',\n",
       " 'Product concordance.ipynb',\n",
       " '0.0 Extract from database.ipynb',\n",
       " 'RC Analisys of fixed effects..ipynb',\n",
       " 'Monthly time series.ipynb',\n",
       " 'Firm baskets CN 4-digit.ipynb',\n",
       " 'Save Growth info.ipynb',\n",
       " 'Plots for experiments 3 and 4.ipynb',\n",
       " 'recovered-blob_020.ipynb',\n",
       " 'Bernard Moxnes comprobation.ipynb',\n",
       " 'Literal Margins.ipynb',\n",
       " 'Dataset totals.ipynb',\n",
       " 'Leontieff aggregation tests.ipynb',\n",
       " 'Higher frequency (Fourier).ipynb',\n",
       " 'Production Network tests.ipynb',\n",
       " 'RC Analisys of fixed effects. Geo dependence.ipynb',\n",
       " 'Experiment 3. Micro shocks. (s, gr).ipynb',\n",
       " 'Leontieff aggregation tests-Copy1.ipynb',\n",
       " 'Growth rates.ipynb',\n",
       " 'Main Plots part 1.ipynb',\n",
       " 'Gabaix Equations Review.ipynb',\n",
       " 'Sourcing strategies.ipynb',\n",
       " 'Autocorrelation of growth rates.ipynb',\n",
       " 'Bernard margins.ipynb',\n",
       " 'Log of sum of powers.ipynb',\n",
       " 'Std of quantiles.ipynb',\n",
       " 'Herfindahl (Nieuwerburgh).ipynb',\n",
       " 'VFTE vs VART.ipynb',\n",
       " 'Determinants of diversification_2.ipynb',\n",
       " 'in-ex margins.ipynb',\n",
       " 'Linear Base + Noise decomposition.ipynb',\n",
       " 'Acemoglu Numerical Tests.ipynb',\n",
       " 'Decomposition terms. w Bootstrap.ipynb',\n",
       " 'Assortativity_2.ipynb',\n",
       " 'Sigma vs log(n), q plots.ipynb',\n",
       " 'Covariance Terms Plots.ipynb',\n",
       " 'Growth rates as shocks from mean.ipynb',\n",
       " 'Degree distribution and assortativity. Diversity.ipynb',\n",
       " 'Size distribution (legacy).ipynb',\n",
       " 'degree data (legacy).ipynb',\n",
       " 'Untitled.ipynb',\n",
       " 'Tendency out of signal.ipynb',\n",
       " 'Data sampling (old).ipynb',\n",
       " 'Countries revealed competitiveness.ipynb',\n",
       " 'Input Output adjacency.ipynb',\n",
       " 'Experiment 2. Extensive BME.ipynb',\n",
       " 'Experiment 4. Micro shocks. (s, gr, size dists).ipynb',\n",
       " 'Firm sizes - old.ipynb',\n",
       " 'sigma vectors with uniform matrix.ipynb',\n",
       " 'Deegree distribution_2.ipynb',\n",
       " 'Effective diversity.ipynb',\n",
       " 'Covariance Terms Bootstrap Experiments.ipynb',\n",
       " 'Xcp by firm size barplots.ipynb',\n",
       " 'Sigma 15 test.ipynb',\n",
       " 'Variance of normal levels vs diff.ipynb',\n",
       " 'Product seasonality.ipynb',\n",
       " 'Harmonize and compare atlas data.ipynb',\n",
       " 'Count buyer-seller links.ipynb',\n",
       " 'Link characteristics.ipynb',\n",
       " 'Devs vs diffs scheme.ipynb',\n",
       " 'Growth rates vs mean divergence vs quantiles.ipynb',\n",
       " 'Partial dependence Computation - 2.ipynb',\n",
       " 'Partial dependence Computation.ipynb',\n",
       " 'Experiment 1. Intensive. (N).ipynb',\n",
       " 'Parabolas. Simulated distribution and growth.ipynb',\n",
       " 'Krammarx regression. Product nw, etc..ipynb',\n",
       " 'Population evolution (violin plots).ipynb',\n",
       " 'Month distribution etc.ipynb',\n",
       " 'Gibrat test.ipynb',\n",
       " 'recovered-blob_041.ipynb',\n",
       " 'Test Exercise Gabaix Riccaboni.ipynb',\n",
       " 'firm names.ipynb',\n",
       " 'Revealed competitiveness (weighted means).ipynb',\n",
       " 'Star vs complete leontieff propagation.ipynb',\n",
       " 'recovered-blob_062.ipynb',\n",
       " 'Partial dependence Analysis.ipynb',\n",
       " 'Experiment 5. Simple var vs nq, s. (s).ipynb',\n",
       " 'Firm basket networks.ipynb']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of growth rates (=random).ipynb\n",
      "Gabaix numerical tests.ipynb\n",
      "Quantile Simulations.ipynb\n",
      "Product concordance.ipynb\n",
      "0.0 Extract from database.ipynb\n",
      "RC Analisys of fixed effects..ipynb\n",
      "Monthly time series.ipynb\n",
      "Firm baskets CN 4-digit.ipynb\n",
      "Save Growth info.ipynb\n",
      "Plots for experiments 3 and 4.ipynb\n",
      "This model's maximum context length is 4097 tokens, however you requested 15568 tokens (14568 in your prompt; 1000 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing notebook: Plots for experiments 3 and 4.ipynb\n",
      "recovered-blob_020.ipynb\n",
      "Bernard Moxnes comprobation.ipynb\n",
      "Literal Margins.ipynb\n",
      "Dataset totals.ipynb\n",
      "Leontieff aggregation tests.ipynb\n",
      "Higher frequency (Fourier).ipynb\n",
      "Production Network tests.ipynb\n",
      "RC Analisys of fixed effects. Geo dependence.ipynb\n",
      "Experiment 3. Micro shocks. (s, gr).ipynb\n",
      "Leontieff aggregation tests-Copy1.ipynb\n",
      "Growth rates.ipynb\n",
      "Main Plots part 1.ipynb\n",
      "This model's maximum context length is 4097 tokens, however you requested 5443 tokens (4443 in your prompt; 1000 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing notebook: Main Plots part 1.ipynb\n",
      "Gabaix Equations Review.ipynb\n",
      "Sourcing strategies.ipynb\n",
      "Autocorrelation of growth rates.ipynb\n",
      "Bernard margins.ipynb\n",
      "Log of sum of powers.ipynb\n",
      "Std of quantiles.ipynb\n",
      "This model's maximum context length is 4097 tokens, however you requested 4112 tokens (3112 in your prompt; 1000 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing notebook: Std of quantiles.ipynb\n",
      "Herfindahl (Nieuwerburgh).ipynb\n",
      "VFTE vs VART.ipynb\n",
      "Determinants of diversification_2.ipynb\n",
      "in-ex margins.ipynb\n",
      "Linear Base + Noise decomposition.ipynb\n",
      "Acemoglu Numerical Tests.ipynb\n",
      "Decomposition terms. w Bootstrap.ipynb\n",
      "Assortativity_2.ipynb\n",
      "Sigma vs log(n), q plots.ipynb\n",
      "This model's maximum context length is 4097 tokens, however you requested 6074 tokens (5074 in your prompt; 1000 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing notebook: Sigma vs log(n), q plots.ipynb\n",
      "Covariance Terms Plots.ipynb\n",
      "This model's maximum context length is 4097 tokens, however you requested 13504 tokens (12504 in your prompt; 1000 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing notebook: Covariance Terms Plots.ipynb\n",
      "Growth rates as shocks from mean.ipynb\n",
      "Degree distribution and assortativity. Diversity.ipynb\n",
      "Size distribution (legacy).ipynb\n",
      "degree data (legacy).ipynb\n",
      "Untitled.ipynb\n",
      "This model's maximum context length is 4097 tokens, however you requested 4442 tokens (3442 in your prompt; 1000 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing notebook: Untitled.ipynb\n",
      "Tendency out of signal.ipynb\n",
      "Data sampling (old).ipynb\n",
      "Countries revealed competitiveness.ipynb\n",
      "Input Output adjacency.ipynb\n",
      "Experiment 2. Extensive BME.ipynb\n",
      "Experiment 4. Micro shocks. (s, gr, size dists).ipynb\n",
      "Firm sizes - old.ipynb\n",
      "sigma vectors with uniform matrix.ipynb\n",
      "Deegree distribution_2.ipynb\n",
      "Effective diversity.ipynb\n",
      "This model's maximum context length is 4097 tokens, however you requested 4974 tokens (3974 in your prompt; 1000 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing notebook: Effective diversity.ipynb\n",
      "Covariance Terms Bootstrap Experiments.ipynb\n",
      "This model's maximum context length is 4097 tokens, however you requested 8283 tokens (7283 in your prompt; 1000 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing notebook: Covariance Terms Bootstrap Experiments.ipynb\n",
      "Xcp by firm size barplots.ipynb\n",
      "Sigma 15 test.ipynb\n",
      "Variance of normal levels vs diff.ipynb\n",
      "Product seasonality.ipynb\n",
      "Harmonize and compare atlas data.ipynb\n",
      "Count buyer-seller links.ipynb\n",
      "Link characteristics.ipynb\n",
      "Devs vs diffs scheme.ipynb\n",
      "Growth rates vs mean divergence vs quantiles.ipynb\n",
      "Partial dependence Computation - 2.ipynb\n",
      "This model's maximum context length is 4097 tokens, however you requested 10282 tokens (9282 in your prompt; 1000 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing notebook: Partial dependence Computation - 2.ipynb\n",
      "Partial dependence Computation.ipynb\n",
      "This model's maximum context length is 4097 tokens, however you requested 4324 tokens (3324 in your prompt; 1000 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing notebook: Partial dependence Computation.ipynb\n",
      "Experiment 1. Intensive. (N).ipynb\n",
      "This model's maximum context length is 4097 tokens, however you requested 5019 tokens (4019 in your prompt; 1000 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing notebook: Experiment 1. Intensive. (N).ipynb\n",
      "Parabolas. Simulated distribution and growth.ipynb\n",
      "Krammarx regression. Product nw, etc..ipynb\n",
      "Population evolution (violin plots).ipynb\n",
      "Month distribution etc.ipynb\n",
      "Gibrat test.ipynb\n",
      "This model's maximum context length is 4097 tokens, however you requested 5166 tokens (4166 in your prompt; 1000 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing notebook: Gibrat test.ipynb\n",
      "recovered-blob_041.ipynb\n",
      "This model's maximum context length is 4097 tokens, however you requested 5082 tokens (4082 in your prompt; 1000 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing notebook: recovered-blob_041.ipynb\n",
      "Test Exercise Gabaix Riccaboni.ipynb\n",
      "firm names.ipynb\n",
      "Revealed competitiveness (weighted means).ipynb\n",
      "Star vs complete leontieff propagation.ipynb\n",
      "recovered-blob_062.ipynb\n",
      "This model's maximum context length is 4097 tokens, however you requested 5159 tokens (4159 in your prompt; 1000 for the completion). Please reduce your prompt; or completion length.\n",
      "Error processing notebook: recovered-blob_062.ipynb\n",
      "Partial dependence Analysis.ipynb\n",
      "Experiment 5. Simple var vs nq, s. (s).ipynb\n",
      "Firm basket networks.ipynb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./../../Notes/summary_code_nbs.md'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Assuming the 'notebooks_content' variable is already populated with the notebook contents\n",
    "# and you have set up your OpenAI API key in your environment\n",
    "\n",
    "# Choose two notebooks for the analysis\n",
    "selected_notebooks = list(notebooks_content.keys())\n",
    "\n",
    "# Initialize an empty string to store the combined API responses\n",
    "api_responses = \"\"\n",
    "openai.api_key = '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'\n",
    "\n",
    "\n",
    "# Process each selected notebook\n",
    "for nb in selected_notebooks:\n",
    "    try:\n",
    "        print(nb)\n",
    "        # Generate the prompt\n",
    "        prompt = prompt_text.format(notebooks_content[nb])\n",
    "\n",
    "        # Call the OpenAI API (this is a dummy call, as API access is not available in this environment)\n",
    "        response = openai.Completion.create(engine=\"text-davinci-003\", prompt=prompt, max_tokens=1000, )\n",
    "        # response = openai.Completion.create(engine=\"gpt-4-0613\", prompt=prompt, max_tokens=500)\n",
    "        api_responses += f\"Notebook: {nb}\\nResponse: {response.choices[0].text}\\n\\n\"\n",
    "\n",
    "        # # Since we can't actually call the API, let's simulate a response\n",
    "        # simulated_response = f\"Simulated analysis for notebook: {nb}\\n\"\n",
    "        # api_responses += simulated_response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Error processing notebook: {nb}\")\n",
    "\n",
    "# Write the responses to a file\n",
    "api_notes_filename = './../../Notes/summary_code_nbs.md'\n",
    "with open(api_notes_filename, 'w') as file:\n",
    "    file.write(api_responses)\n",
    "\n",
    "api_notes_filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./API_notes_2.md'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the responses to a file\n",
    "api_notes_filename = './API_notes_2.md'\n",
    "with open(api_notes_filename, 'w') as file:\n",
    "    file.write(api_responses)\n",
    "\n",
    "api_notes_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x7f9fa708fe30> JSON: {\n",
       "  \"object\": \"list\",\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"id\": \"text-search-babbage-doc-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172509,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"gpt-4-0613\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1686588896,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"curie-search-query\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172509,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"gpt-4\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1687882411,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-davinci-003\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1669599635,\n",
       "      \"owned_by\": \"openai-internal\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-search-babbage-query-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172509,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"babbage\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649358449,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"babbage-search-query\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172509,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-babbage-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649364043,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-similarity-davinci-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172505,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"davinci-similarity\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172509,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"curie-similarity\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172510,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"babbage-search-document\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172510,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"curie-instruct-beta\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649364042,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-search-ada-doc-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172507,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"gpt-3.5-turbo-0301\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1677649963,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"davinci-instruct-beta\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649364042,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"gpt-3.5-turbo-16k-0613\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1685474247,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-similarity-babbage-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172505,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-search-davinci-doc-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172505,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"babbage-similarity\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172505,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-embedding-ada-002\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1671217299,\n",
       "      \"owned_by\": \"openai-internal\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"davinci-search-query\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172505,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-similarity-curie-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172507,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"gpt-3.5-turbo-instruct\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1692901427,\n",
       "      \"owned_by\": \"system\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-davinci-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649364042,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-search-davinci-query-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172505,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"ada-search-document\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172507,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"ada-code-search-code\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172505,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"babbage-002\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1692634615,\n",
       "      \"owned_by\": \"system\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"gpt-3.5-turbo-1106\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1698959748,\n",
       "      \"owned_by\": \"system\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"davinci-002\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1692634301,\n",
       "      \"owned_by\": \"system\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"gpt-3.5-turbo-instruct-0914\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1694122472,\n",
       "      \"owned_by\": \"system\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"davinci-search-document\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172509,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"curie-search-document\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172508,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"babbage-code-search-code\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172509,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-search-ada-query-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172505,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"code-search-ada-text-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172507,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"gpt-3.5-turbo-0613\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1686587434,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"babbage-code-search-text\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172509,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"gpt-4-vision-preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1698894917,\n",
       "      \"owned_by\": \"system\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"code-search-babbage-code-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172507,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"ada-search-query\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172505,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"ada-code-search-text\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172510,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"tts-1-hd\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1699046015,\n",
       "      \"owned_by\": \"system\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-search-curie-query-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172509,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-davinci-002\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649880484,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"code-search-babbage-text-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172507,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"gpt-4-1106-preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1698957206,\n",
       "      \"owned_by\": \"system\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"ada\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649357491,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-ada-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649364042,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"ada-similarity\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172507,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"code-search-ada-code-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172507,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-similarity-ada-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172505,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-davinci-edit-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649809179,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"gpt-3.5-turbo\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1677610602,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"code-davinci-edit-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649880484,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-search-curie-doc-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172509,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"whisper-1\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1677532384,\n",
       "      \"owned_by\": \"openai-internal\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-curie-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649364043,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"curie\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649359874,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"tts-1\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1681940951,\n",
       "      \"owned_by\": \"openai-internal\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"davinci\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649359874,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"dall-e-2\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1698798177,\n",
       "      \"owned_by\": \"system\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"gpt-4-0314\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1687882410,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"tts-1-1106\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1699053241,\n",
       "      \"owned_by\": \"system\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"tts-1-hd-1106\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1699053533,\n",
       "      \"owned_by\": \"system\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"gpt-3.5-turbo-16k\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1683758102,\n",
       "      \"owned_by\": \"openai-internal\"\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install --upgrade openai\n",
    "openai.Model.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
