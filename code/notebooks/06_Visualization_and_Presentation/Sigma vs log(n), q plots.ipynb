{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# size dist plus growth rates\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "% matplotlib inline\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import pareto\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.special import erf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical number of agents and total value\n",
    "Recommendation: \n",
    "\n",
    "1e5 agents. \n",
    "\n",
    "~1e11.5 EUR annually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eg levels = (np.arange(Q)/Q)[::2]\n",
    "\n",
    "def plot_levels_reflex(levels, ax):\n",
    "    for level in levels:\n",
    "        ax.axhline(level, lw = .4, c = 'k', alpha = .5)\n",
    "        ax.axvline(level, lw = .4, c = 'k')\n",
    "        ax.fill_between([0, 1], [0, 1], color = 'w', zorder = 10)\n",
    "        ax.set_xlim(-0.12, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        plt.axis('off')\n",
    "    # ax.plot(levels, levels, '+', markersize = 15, c = '.5')\n",
    "    ax.plot(levels, len(levels)*[.98], '^', markersize = 8, c = '.5')\n",
    "    \n",
    "    # Now we can have the n(Q, q)\n",
    "def get_n(x1, Q):\n",
    "    x_lin = np.power(10, x1)\n",
    "    bins = pd.cut(pd.Series(np.cumsum(x_lin)), Q)\n",
    "    ns = bins.value_counts().values\n",
    "    return bins, ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#1f77b4',\n",
       " '#ff7f0e',\n",
       " '#2ca02c',\n",
       " '#d62728',\n",
       " '#9467bd',\n",
       " '#8c564b',\n",
       " '#e377c2',\n",
       " '#7f7f7f',\n",
       " '#bcbd22',\n",
       " '#17becf']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "pal = sns.color_palette('tab10')\n",
    "pal.as_hex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical GR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## List the datasets for quicker access\n",
    "\n",
    "# rows = []\n",
    "# for sizes in ['pareto', 'logn90', 'logn']:\n",
    "#     cols = []\n",
    "#     for k, dist in enumerate(['sbtn', 'lapl', 'norm']):        \n",
    "#         filename = './../../data/processed/exp_var_'+dist+'_1s_'+sizes+'.csv'\n",
    "#         data = pd.read_csv(filename)\n",
    "#         cols += [data]\n",
    "#     rows += [cols]\n",
    "# data = rows\n",
    "\n",
    "# # data:\n",
    "# #         sbtn , lapl, norm\n",
    "# # pareto\n",
    "# # logn90\n",
    "# # logn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In this one, all points go one after the other..\n",
    "# fig, axs = plt.subplots(3, figsize = (15, 12))\n",
    "\n",
    "# for i, sizes in enumerate(['pareto', 'logn90', 'logn']):\n",
    "#     for j, dist in enumerate(['sbtn', 'lapl', 'norm']):\n",
    "#         ax = axs[i]\n",
    "#         result = data[i][j]\n",
    "#         result = result.loc[result.Q == 10]\n",
    "        \n",
    "# #         result['t'] = result['var_diff_qi']/(result['s']**2)\n",
    "#         y = 'var_diff_qi'\n",
    "#         sorted_ = result.sort_values(by = ['dist','s', 'q', y])\n",
    "#         [ax.axvline(l, linestyle = '--') for l in sorted_.groupby(['dist','s', 'q']).count().iloc[:, 0].cumsum().values]\n",
    "#         [ax.axvline(l, lw = 2) for l in sorted_.groupby(['s','Q']).count().iloc[:, 0].cumsum().values]\n",
    "#         sorted_.reset_index()[[y]].plot(ax = ax, marker = '.', lw = 0, label = sizes)\n",
    "# #         sorted_.reset_index()[['var_diff_agg_i']].plot(ax = ax, marker = '.', lw = 0, c = '.5', alpha = .1, legend = False)\n",
    "#         ax.set_yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile volatilities and aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(3, 3, figsize = (15, 12))\n",
    "\n",
    "    \n",
    "# for i, sizes in enumerate(['pareto', 'logn90', 'logn']):\n",
    "#     for j, dist in enumerate(['sbtn', 'lapl', 'norm']):\n",
    "#         ax = axs[i][j]\n",
    "#         ax.set_title(sizes +', '+ dist)\n",
    "#         result = data3[i][j]\n",
    "#         result = result.loc[result.Q == 20]\n",
    "\n",
    "#         y = 'var_diff_qi'\n",
    "#         sorted_ = result.sort_values(by = ['dist','s', 'q', y])\n",
    "#         for k, s in enumerate(sorted_.s.unique()):\n",
    "#             sorted_s = sorted_.loc[sorted_.s == s]\n",
    "#             sorted_s.reset_index()[[y]].plot(ax = ax, marker = '.', lw = 0, c = colors[k])\n",
    "# #                     sorted_s.reset_index()[['var_diff_agg_i']].plot(ax = ax, marker = '.', lw = 0, c = colors[k], alpha = .1, legend = False)\n",
    "#             agg_vals = sorted_s.reset_index()['var_diff_agg_i'].describe()\n",
    "#             ax.fill_between(range(len(sorted_s)), agg_vals['25%'], agg_vals['75%'], color = colors[k], alpha = .35, zorder = 10)\n",
    "\n",
    "#         ax.legend(sorted_.s.unique(), loc = (1, 0))\n",
    "#         [ax.axvline(l, linestyle = '--') for l in sorted_s.groupby(['q']).count().iloc[:, 0].cumsum().values]\n",
    "#         ax.set_yscale('log')\n",
    "\n",
    "# plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in the empiricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check slopes because of bias in log when growth rates diffuse.\n",
    "# Conclusion: slope given by grs ('dist') and s \n",
    "\n",
    "# fig, ax = plt.subplots(1, figsize = (17, 6))\n",
    "\n",
    "# for j, sizes in enumerate(['pareto', 'logn90', 'logn']):\n",
    "#     for k, dist in enumerate(['emp_szd_T16', 'lapl', 'norm']):  \n",
    "#         if k < 10:\n",
    "#             df = data2[j][k]\n",
    "#             df['pct'] = (df['q'] + .5)/df['Q']\n",
    "#             df = df.loc[df.pct < .2]\n",
    "\n",
    "#             linear_bias = df.groupby(['dist', 'sizes', 's', 'Q', 'q'])[[str(t) for t in range(T + 1)]].apply(lambda x: np.log10(x).mean().diff()).dropna(axis = 1)\n",
    "\n",
    "#             linear_bias.columns = linear_bias.columns.astype(int)\n",
    "#             slopes = linear_bias.T.apply(lambda x: np.polyfit(linear_bias.columns, x, 1)[0])\n",
    "\n",
    "#             pd.DataFrame(abs(slopes), columns = ['slope']).plot(ax = ax)\n",
    "#             ax.legend(sizes+', '+dist)\n",
    "\n",
    "# plt.legend()\n",
    "# plt.yscale('log')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load simulated data\n",
    "## Subtract border condition bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List the datasets for quicker access\n",
    "\n",
    "T = 15\n",
    "\n",
    "rows = []\n",
    "for sizes in ['pareto', 'logn90', 'logn']:\n",
    "    cols = []\n",
    "    for k, dist in enumerate(['sbtn','emp_szd_T16_clip.8','emp_szd_T16', 'lapl', 'norm']):        \n",
    "\n",
    "        if dist == 'emp_szd_T16_clip.8':\n",
    "            df = pd.read_csv('./../../data/processed/exp_var_'+dist+'_1s_'+sizes+'_7s_70Qqs_200i_.csv')\n",
    "            \n",
    "        else:\n",
    "            df1 = pd.read_csv('./../../data/processed/exp_var_'+dist+'_1s_'+sizes+'_5s_70Qqs_200i_.csv')\n",
    "            df2 = pd.read_csv('./../../data/processed/exp_var_'+dist+'_1s_'+sizes+'_2s_70Qqs_200i_.csv')\n",
    "\n",
    "            if dist == 'emp_szd_T16':\n",
    "                df2['var_diff_qi'] = np.log10(df2[[str(t) for t in range(T)]]).diff(axis = 1).var(axis = 1) #fix previous problem\n",
    "            df = pd.concat([df1, df2])\n",
    "        \n",
    "        I = df['i'].max() + 1; keep = int(.5*I)    \n",
    "        ### \n",
    "        # DROP CASES WHERE QUANTILES ARE FAR FROM BALANCED\n",
    "        ###\n",
    "        df = df.reset_index().set_index(['s','Q', 'q', 'i'])\n",
    "        df_lin_vals = df[[str(t) for t in range(T + 1)]]\n",
    "        grouped = df_lin_vals.mean(1).groupby(level = [0, 1, 3]) \n",
    "        acceptables = (np.log10(grouped.max()) - np.log10(grouped.min())).groupby(level = [0, 1]).nsmallest(keep).sort_index()\n",
    "        acceptables.index = acceptables.index.droplevel([0, 1])\n",
    "        df = df.reset_index().set_index(['s', 'Q', 'i']).loc[acceptables.index].reset_index()#.set_index(['Q', 's', 'i'])\n",
    "        table = df\n",
    "            \n",
    "            \n",
    "#         table = pd.read_csv(filename)\n",
    "        cols += [table]\n",
    "    rows += [cols]\n",
    "data2 = rows\n",
    "\n",
    "# data:\n",
    "#         sbtn , lapl, norm\n",
    "# pareto\n",
    "# logn90\n",
    "# logn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Concatenate if wanted\n",
    "\n",
    "# T = 15\n",
    "\n",
    "# df_list = []\n",
    "# for j, sizes in enumerate(['pareto', 'logn90', 'logn']):\n",
    "#     for k, dist in enumerate(['emp_szd_T16_clip.8','emp_szd_T16', 'lapl', 'norm', 'sbtn']):  \n",
    "#         df_list += [data2[j][k]]\n",
    "# data3 = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data 2 es lista 2d de 3 x 5 x df.\n",
    "\n",
    "pd.DataFrame(data2[0])\n",
    "len(data2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emp_szd_T16_clip.8\n",
      "[ 0.2093882  -0.00080247]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df = data3.copy()\n",
    "df = data2[1][1]\n",
    "df['pct'] = (df['q'] + .5)/df['Q']\n",
    "df = df.loc[df.pct < .2]\n",
    "\n",
    "linear_bias = df.groupby(['dist', 'sizes', 's', 'Q', 'q'])[[str(t) for t in range(T + 1)]].apply(lambda x: np.log10(x).mean().diff()).dropna(axis = 1)\n",
    "\n",
    "linear_bias.columns = linear_bias.columns.astype(int)\n",
    "slopes = linear_bias.T.apply(lambda x: np.polyfit(linear_bias.columns, x, 1)[0])\n",
    "slopes = pd.DataFrame(abs(slopes), columns = ['slope'])\n",
    "\n",
    "# df['empirical'] = df.index.get_level_values('dist') == 'emp_szd_T16'\n",
    "\n",
    "slopes = slopes.reset_index()\n",
    "# slopes['empirical'] = slopes['dist'] == 'emp_szd_T16'\n",
    "bias_slope = slopes.groupby(['sizes','dist', 's'])['slope'].mean().reset_index()\n",
    "bias_slope['s2'] = bias_slope['s']**2\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (7, 5))\n",
    "# for i in [0, 1]:\n",
    "#     part = bias_slope.loc[bias_slope.empirical == i]\n",
    "\n",
    "for dist in bias_slope.dist.unique():\n",
    "    print(dist)\n",
    "    part = bias_slope.loc[bias_slope.dist == dist]\n",
    "    part.plot(x = 's2', y = 'slope', ax = ax, marker = '.')\n",
    "    print(np.polyfit(part.s2, part.slope,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtract bias in time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "size_distributions = ['pareto', 'logn90', 'logn']\n",
    "growth_rates = ['emp_szd_T16_clip.8','emp_szd_T16', 'lapl', 'norm', 'sbtn']\n",
    "        \n",
    "rows = []\n",
    "for i, sizes in enumerate(size_distributions):\n",
    "    cols = []        \n",
    "    for j, dist in enumerate(growth_rates):\n",
    "        df = data2[i][j]\n",
    "        \n",
    "        ## Slopes\n",
    "        if dist == 'emp_szd_T16': df['slope'] = 0.0896*df['s']**2\n",
    "        elif dist == 'emp_szd_T16_clip.8': df['slope'] = 0.2236*df['s']**2\n",
    "        elif dist == 'sbtn': df['slope'] = 0.1096*df['s']**2\n",
    "        else: df['slope'] = 0.136*df['s']**2\n",
    "\n",
    "            \n",
    "        ## qi level\n",
    "        diff = np.log10(df[[str(t) for t in range(T + 1)]]).diff(axis = 1)\n",
    "        bias = pd.DataFrame(np.array((T + 1)*[-df['slope'].values]).T*range(T + 1))\n",
    "        bias.columns = diff.columns\n",
    "        df['var_diff_qi'] = (diff - bias).var(1) # in place of diff.var(1)\n",
    "        \n",
    "        ## i experiment level\n",
    "        grouped = df.groupby(['dist', 'sizes', 's', 'Q', 'i'])\n",
    "        diff_agg = grouped[[str(t) for t in range(T + 1)]].apply(lambda x: np.log10(x.sum()).diff())#.tail(20).T.plot(legend = False)\n",
    "        bias_agg = pd.DataFrame(np.array((T + 1)*[-grouped['slope'].first().values]).T*range(T + 1))\n",
    "        bias_agg.columns = diff_agg.columns\n",
    "        bias_agg.index = diff_agg.index\n",
    "        df_agg = (diff_agg - bias_agg).var(1)\n",
    "        df_agg.name = 'var_diff_agg_i'\n",
    "\n",
    "        df = df.drop('var_diff_agg_i', axis = 1)\n",
    "        df = df.merge(df_agg.reset_index())\n",
    "#         agg var oneliner: result.groupby(['dist', 'sizes', 's', 'Q', 'i'])[[str(t) for t in range(T + 1)]].apply(lambda x: np.log10(x.sum()).diff().var())\n",
    "#         df_list += [df]\n",
    "# data3 = pd.concat(df_list)\n",
    "\n",
    "        cols += [df]\n",
    "    rows += [cols]\n",
    "data3 = rows\n",
    "\n",
    "# plt.plot(a.values, b.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.concat(list(np.array(data3).flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.to_csv('./../../data/processed/full_data_qi_var.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out[['var_diff_agg_i', 'test']].plot(alpha = .4)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, do plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_csv('./../../data/processed/full_data_qi_var.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "pal = sns.color_palette('tab10')\n",
    "colors = pal.as_hex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_distributions = ['logn']\n",
    "growth_rates = ['norm', 'lapl', 'sbtn']\n",
    "\n",
    "fig, axs = plt.subplots(len(size_distributions), len(growth_rates), figsize = (5*len(growth_rates), 4*len(size_distributions)))\n",
    "        \n",
    "Q = 20\n",
    "for i, sizes in enumerate(size_distributions):\n",
    "    for j, dist in enumerate(growth_rates):\n",
    "        ax = axs[j]\n",
    "        ax.set_title(['Normal', 'Laplace', 'Subbotin -1/2', 'Empirical, clipped at .8', 'Empirical'][j])\n",
    "        result = full_data.loc[(full_data.sizes == sizes) & (full_data.dist == dist)]\n",
    "        result = result.loc[result.Q == Q]\n",
    "\n",
    "        y = 'var_diff_qi'\n",
    "        sorted_ = result.sort_values(by = ['dist','s', 'q', y], ascending = [True, False, False, True])\n",
    "        Ss = sorted_.s.unique()[::2]\n",
    "        for k, s in enumerate(Ss):\n",
    "            sorted_s = sorted_.loc[sorted_.s == s]\n",
    "            sorted_s.reset_index()[[y]].plot(ax = ax, marker = '.', lw = 0, c = colors[k])\n",
    "#                     sorted_s.reset_index()[['var_diff_agg_i']].plot(ax = ax, marker = '.', lw = 0, c = colors[k], alpha = .1, legend = False)\n",
    "            agg_vals = sorted_s.reset_index()['var_diff_agg_i'].describe()\n",
    "            ax.fill_between(range(len(sorted_s)), agg_vals['25%'], agg_vals['75%'], color = colors[k], alpha = .35, zorder = -1)\n",
    "        \n",
    "            ax.xaxis.set_ticks(np.arange(0, (Q)*100, 100) + 100/2)\n",
    "            ax.xaxis.set_ticklabels(np.arange(Q) + 1)\n",
    "\n",
    "            if j == 2: \n",
    "                ax.legend([s for s in Ss]+[r'aggregate $\\sigma^2$'], title=r'$\\bar \\sigma^2_j$', loc = (1.02, 0))\n",
    "            else:\n",
    "                ax.get_legend().remove()\n",
    "#             legend = plt.legend(handles=[one, two, three], title=\"title\", loc=4, fontsize='small', fancybox=True)\n",
    "            \n",
    "        [ax.axvline(l, linestyle = '--') for l in sorted_s.groupby(['q']).count().iloc[:, 0].cumsum().values]\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_ylim(1e-8, 1e1)\n",
    "        ax.set_ylabel('variance', fontsize = 13)\n",
    "        ax.set_xlabel('quantiles q', fontsize = 13)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./../../../WRITING/paper1_writing/figures/quantile_depce_iid.png', dpi = 400)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_distributions = ['logn']\n",
    "growth_rates = ['emp_szd_T16_clip.8', 'emp_szd_T16']\n",
    "\n",
    "fig, axs = plt.subplots(len(size_distributions), len(growth_rates), figsize = (5*len(growth_rates), 4*len(size_distributions)),\n",
    "                        sharey = True, sharex = True)\n",
    "\n",
    "Q = 20\n",
    "for i, sizes in enumerate(size_distributions):\n",
    "    for j, dist in enumerate(growth_rates):\n",
    "        ax = axs[j]\n",
    "        ax.set_title(['Empirical, clipped at .8', 'Empirical'][j])\n",
    "        result = full_data.loc[(full_data.sizes == sizes) & (full_data.dist == dist)]\n",
    "        result = result.loc[result.Q == Q]\n",
    "\n",
    "        y = 'var_diff_qi'\n",
    "        sorted_ = result.sort_values(by = ['dist','s', 'q', y], ascending = [True, False, False, True])\n",
    "        Ss = sorted_.s.unique()[::2]\n",
    "        for k, s in enumerate(Ss):\n",
    "            sorted_s = sorted_.loc[sorted_.s == s]\n",
    "            sorted_s.reset_index()[[y]].plot(ax = ax, marker = '.', lw = 0, c = colors[k])\n",
    "#                     sorted_s.reset_index()[['var_diff_agg_i']].plot(ax = ax, marker = '.', lw = 0, c = colors[k], alpha = .1, legend = False)\n",
    "            agg_vals = sorted_s.reset_index()['var_diff_agg_i'].describe()\n",
    "            ax.fill_between(range(len(sorted_s)), agg_vals['25%'], agg_vals['75%'], color = colors[k], alpha = .35, zorder = -1)\n",
    "        \n",
    "            ax.xaxis.set_ticks(np.arange(0, (Q)*100, 100) + 100/2)\n",
    "            ax.xaxis.set_ticklabels(np.arange(Q) + 1)\n",
    "            if j == 1: \n",
    "                ax.legend([str(2*s) for s in Ss]+[r'aggregate $\\sigma^2$'], title='shock \\n magnification', loc = (1.02, 0))\n",
    "            else:\n",
    "                ax.get_legend().remove()\n",
    "            \n",
    "#             legend = plt.legend(handles=[one, two, three], title=\"title\", loc=4, fontsize='small', fancybox=True)\n",
    "            \n",
    "        [ax.axvline(l, linestyle = '--') for l in sorted_s.groupby(['q']).count().iloc[:, 0].cumsum().values]\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_ylabel('variance', fontsize = 13)\n",
    "        ax.set_xlabel('quantiles q', fontsize = 13)\n",
    "        ax.set_ylim(1e-8, 1e1)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./../../../WRITING/paper1_writing/figures/quantile_depce_empirical.png', dpi = 300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "size_distributions = ['pareto', 'logn90', 'logn']\n",
    "growth_rates = ['norm', 'lapl', 'sbtn', 'emp_szd_T16_clip.8','emp_szd_T16']\n",
    "Q = 15\n",
    "\n",
    "fig, axs = plt.subplots(len(growth_rates), len(size_distributions), figsize = (4.5*len(size_distributions), 3.5*len(growth_rates)),\n",
    "                       sharey = True, sharex = True)\n",
    "\n",
    "size_names = ['Pareto', 'Lognormal 90%', 'Lognormal']\n",
    "dist_names = ['normal iid', 'Laplace iid', 'Subbotin -1/2 iid','Empirical, clipped at .8', 'Empirical']\n",
    "for i, sizes in enumerate(size_distributions):\n",
    "    for j, dist in enumerate(growth_rates):\n",
    "        ax = axs[j][i]\n",
    "        ax.set_title(size_names[i] +', '+ dist_names[j])\n",
    "        result = full_data.loc[(full_data.sizes == sizes) & (full_data.dist == dist)]\n",
    "        result = result.loc[result.Q == Q]\n",
    "\n",
    "        y = 'var_diff_qi'\n",
    "        sorted_ = result.sort_values(by = ['dist','s', 'q', y], ascending = [True, False, False, True])\n",
    "        Ss = sorted_.s.unique()[::2]\n",
    "        for k, s in enumerate(Ss):\n",
    "            sorted_s = sorted_.loc[sorted_.s == s]\n",
    "            sorted_s.reset_index()[[y]].plot(ax = ax, marker = '.', lw = 0, c = colors[k])\n",
    "#                     sorted_s.reset_index()[['var_diff_agg_i']].plot(ax = ax, marker = '.', lw = 0, c = colors[k], alpha = .1, legend = False)\n",
    "            agg_vals = sorted_s.reset_index()['var_diff_agg_i'].describe()\n",
    "            ax.fill_between(range(len(sorted_s)), agg_vals['25%'], agg_vals['75%'], color = colors[k], alpha = .35, zorder = -1)\n",
    "        \n",
    "            ax.xaxis.set_ticks(np.arange(0, (Q)*100, 100) + 100/2)\n",
    "            ax.xaxis.set_ticklabels(np.arange(Q) + 1)\n",
    "            \n",
    "        if i == len(size_distributions) - 1:\n",
    "            if j <= 2: ax.legend([s for s in Ss]+[r'aggregate $\\sigma^2$'], title=r'$\\bar \\sigma^2_j$', loc = (1.02, 0))\n",
    "            if j > 2: ax.legend([str(2*s) for s in Ss]+[r'aggregate $\\sigma^2$'], title='shock \\n magnification', loc = (1.02, 0))        \n",
    "        else:\n",
    "            ax.get_legend().remove()\n",
    "\n",
    "        [ax.axvline(l, linestyle = '--') for l in sorted_s.groupby(['q']).count().iloc[:, 0].cumsum().values]\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_ylim(1e-7, 1)\n",
    "        if i == 0: ax.set_ylabel('variance', fontsize = 13)\n",
    "        if j == len(growth_rates) - 1: ax.set_xlabel('quantiles q', fontsize = 13)\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('./../../../WRITING/paper1_writing/figures/quantile_depce_supplement.png', dpi = 250)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i, sizes in enumerate(size_distributions):\n",
    "#     for j, dist in enumerate(growth_rates):\n",
    "#         print(sizes +', '+ dist)\n",
    "#         display(data3[i][j].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_rates = ['emp_szd_T16_clip.8']#, 'emp_szd_T16', 'lapl']\n",
    "fig, axs = plt.subplots(len(growth_rates), 4, figsize = (15, 4*len(growth_rates)), sharey = True)\n",
    "\n",
    "sizes = 'logn90'\n",
    "for i, dist in enumerate(growth_rates):\n",
    "    result = full_data.loc[(full_data.sizes == sizes) & (full_data.dist == dist)]\n",
    "    y = 'var_diff_qi'\n",
    "    sorted_ = result.sort_values(by = ['dist','s', 'q', y], ascending = [True, False, False, True])\n",
    "    for j, Q in enumerate(result.Q.unique()):\n",
    "        ax = axs[j]  #[i][j]\n",
    "#         ax.set_title(sizes +', '+ dist + ', '+ str(Q))\n",
    "        ax.set_title('Q = '+ str(Q))\n",
    "\n",
    "        sorted_Q = sorted_.loc[sorted_.Q == Q]\n",
    "        Ss = sorted_.s.unique()[::2]\n",
    "        for k, s in enumerate(Ss):\n",
    "            sorted_s = sorted_Q.loc[sorted_Q.s == s]\n",
    "            sorted_s.reset_index()[[y]].plot(ax = ax, marker = '.', lw = 0, c = colors[k])\n",
    "#                     sorted_s.reset_index()[['var_diff_agg_i']].plot(ax = ax, marker = '.', lw = 0, c = colors[k], alpha = .1, legend = False)\n",
    "            agg_vals = sorted_s.reset_index()['var_diff_agg_i'].describe()\n",
    "            ax.fill_between(range(len(sorted_s)), agg_vals['25%'], agg_vals['75%'], color = colors[k], alpha = .35, zorder = 10)\n",
    "\n",
    "        ax.legend(Ss, loc = (1, 0))\n",
    "        ax.axhline(Q/100000, linestyle = '--', c = 'k', lw = 1)\n",
    "        ax.axhline(10/100000, linestyle = '-', c = 'k', lw = 1)\n",
    "        [ax.axvline(l, linestyle = '--') for l in sorted_s.groupby(['q']).count().iloc[:, 0].cumsum().values]\n",
    "        ax.set_ylim(1e-7, 1)\n",
    "        ax.set_yscale('log')\n",
    "        \n",
    "        if j == 3:\n",
    "            ax.legend([str(2*s) for s in Ss]+['Q offset'], title='shock \\n magnification', loc = (1.02, 0))        \n",
    "        else:\n",
    "            ax.get_legend().remove()\n",
    "            \n",
    "        ax.xaxis.set_ticks(np.arange(0, (Q)*100, 100) + 100/2)\n",
    "        ax.xaxis.set_ticklabels(np.arange(Q) + 1, rotation = 45, ha = 'right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./../../../paper1_writing/figures/Q_offset.png', dpi = 400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate size distribution params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can have the n(Q, q)\n",
    "def get_n(x1, Q):\n",
    "    x_lin = np.power(10, x1)\n",
    "    bins = pd.cut(pd.Series(np.cumsum(x_lin)), Q)\n",
    "    ns = bins.value_counts().values\n",
    "    return bins, ns\n",
    "\n",
    "#  - Lognormal clipped x > 3. \n",
    "sigma = 1.2810683494198207 # 1.3149476902828778\n",
    "mu = 4.536908110675739 # 4.470439741406725\n",
    "# 13% of guys that would be below the .3 threshold.\n",
    "z = (mu - 3)/sigma\n",
    "cum_th = 1 - .5*(1 + erf(z/np.sqrt(2)))\n",
    "# From the theoretical N and the ppf we can know the theoretical quantiles\n",
    "N = int(1e5)\n",
    "N_ = int(round(N/(1 - cum_th))) # We use a larger N ..\n",
    "x_logn_clip3 = np.array([norm.ppf(q, mu, sigma) for q in np.arange(0, 1, 1/N_) + .5/N_])\n",
    "x_logn_clip3 = x_logn_clip3[(-N - 1):-1]\n",
    "\n",
    "## N tail for pareto and lognormal tail\n",
    "N_tail = get_n(x_logn_clip3, 10)[1][1:].sum()\n",
    "x_logn_clip3_90 = x_logn_clip3[-N_tail:]\n",
    "\n",
    "# PARETO\n",
    "z_0 = -1.1042021 #-1.1771\n",
    "# value_qs_1 = x_logn_clip3_90.min() # 6.761 in the original fit\n",
    "value_qs_1 = 6.67465\n",
    "\n",
    "norm_const = 1.375\n",
    "x1 = np.array([pareto.ppf(b = -z_0, scale = 10**value_qs_1, q = q) for q in np.arange(0, 1, 1/(norm_const*N_tail)) + .5/(norm_const*N_tail)])\n",
    "np.log10(pareto.rvs(b = -z_0, size = N_tail, scale = 10**value_qs_1) + 1)\n",
    "x1 = x1[int(-norm_const*N_tail - 1):-1]\n",
    "x_pareto = np.log10(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (9, 4.5), sharey = True, sharex = True)\n",
    "\n",
    "# Q_ = 20\n",
    "for Q_ in [10]:\n",
    "    for i, sizes in enumerate(['logn']):\n",
    "        for l in [0, 1]:\n",
    "            for j, dist in enumerate([['emp_szd_T16_clip.8', 'sbtn'],\n",
    "                                     ['lapl', 'norm']][l]):\n",
    "                bins, ns = get_n(x_logn_clip3, Q_) #[x_pareto, x_logn_clip3, x_logn_clip3_90]\n",
    "                ax = axs[l]\n",
    "                ax.set_title(['Empirical (clip .8), Subbotin 1/2', 'Normal, Laplace'][l])\n",
    "                result = full_data.loc[(full_data.sizes == sizes) & (full_data.dist == dist)]\n",
    "                result = result.loc[result.Q == Q_]\n",
    "\n",
    "                y = 'var_diff_qi'\n",
    "\n",
    "               #  Merge the Ns\n",
    "                ns = pd.DataFrame([range(Q_), ns], index = ['q', 'n']).T\n",
    "                result = result.merge(ns, on = 'q')\n",
    "                result['log_n'] = np.log10(result.n)\n",
    "        #         result['log_var_diff_qi'] = np.log10(result.var_diff_qi)\n",
    "\n",
    "                sorted_ = result.sort_values(by = ['dist','s', 'q', y])\n",
    "                Ss = sorted_.s.unique()[::2]\n",
    "                for k, s in enumerate(Ss):\n",
    "                    sorted_s = sorted_.loc[sorted_.s == s]\n",
    "        #             sorted_s.reset_index()[[y]].plot(ax = ax, marker = '.', lw = 0, c = colors[k])\n",
    "        #                     sorted_s.reset_index()[['var_diff_agg_i']].plot(ax = ax, marker = '.', lw = 0, c = colors[k], alpha = .1, legend = False)\n",
    "                    agg_vals = sorted_s.reset_index()['var_diff_agg_i'].describe()\n",
    "                    bin_vals = sorted_s.groupby('n')['var_diff_qi'].describe()\n",
    "\n",
    "                    xn = bin_vals.index.values\n",
    "    #                 ax.plot([xn.min(), xn.max()], [agg_vals['50%'], agg_vals['50%']], color = colors[k], alpha = .6, zorder = 10)\n",
    "                    ax.plot([xn.min(), xn.max()], [.0002/xn.min(), .0002/xn.max()], color = '.5', alpha = .6, zorder = 10, lw = 1, label = '1/n dependence', linestyle = '--')\n",
    "                    ax.fill_between(xn, bin_vals['25%'], bin_vals['75%'], color = colors[k], alpha = .35, zorder = 10)\n",
    "                    ax.plot(xn, bin_vals['50%'], color = 'w', zorder = 10, marker = '.', lw = 0, alpha = .7)\n",
    "\n",
    "#                 ax.legend(Ss, loc = (1, 0))\n",
    "        #         [ax.axvline(l, linestyle = '--') for l in sorted_s.groupby(['q']).count().iloc[:, 0].cumsum().values]\n",
    "                ax.set_xscale('log')\n",
    "                ax.set_xlim(5, 2e5)\n",
    "\n",
    "                ax.set_yscale('log')\n",
    "                ax.set_ylim(1e-8, 10)\n",
    "                ax.legend().remove()\n",
    "                ax.set_ylabel('variance '+r'$\\sigma^2$', fontsize = 12)\n",
    "                ax.set_xlabel('log(n)', fontsize = 12)\n",
    "\n",
    "plt.savefig('./../../../paper1_writing/figures/sigma_vs_n_grs.png', dpi = 400)\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (9, 4.5), sharey = True, sharex = True)\n",
    "\n",
    "# Q_ = 20\n",
    "for Q_ in [10]:\n",
    "    for i, sizes in enumerate(['logn90', 'pareto']):\n",
    "#         for l in [0, 1]:\n",
    "#             for j, dist in enumerate([['emp_szd_T16_clip.8', 'sbtn'],\n",
    "#                                      ['lapl', 'norm']][l]):\n",
    "        for j, dist in enumerate(['emp_szd_T16_clip.8', 'norm']):\n",
    "            bins, ns = get_n([x_logn_clip3_90, x_pareto][i], Q_) #[x_pareto, x_logn_clip3, x_logn_clip3_90]\n",
    "            ax = axs[j]\n",
    "            ax.set_title(['Empirical growth rates', 'Normal log growth rates'][j])\n",
    "            result = full_data.loc[(full_data.sizes == sizes) & (full_data.dist == dist)]\n",
    "            result = result.loc[result.Q == Q_]\n",
    "\n",
    "            y = 'var_diff_qi'\n",
    "\n",
    "           #  Merge the Ns\n",
    "            ns = pd.DataFrame([range(Q_), ns], index = ['q', 'n']).T\n",
    "            result = result.merge(ns, on = 'q')\n",
    "            result['log_n'] = np.log10(result.n)\n",
    "    #         result['log_var_diff_qi'] = np.log10(result.var_diff_qi)\n",
    "\n",
    "            sorted_ = result.sort_values(by = ['dist','s', 'q', y])\n",
    "            Ss = sorted_.s.unique()[::2]\n",
    "            for k, s in enumerate(Ss):\n",
    "                sorted_s = sorted_.loc[sorted_.s == s]\n",
    "    #             sorted_s.reset_index()[[y]].plot(ax = ax, marker = '.', lw = 0, c = colors[k])\n",
    "    #                     sorted_s.reset_index()[['var_diff_agg_i']].plot(ax = ax, marker = '.', lw = 0, c = colors[k], alpha = .1, legend = False)\n",
    "                agg_vals = sorted_s.reset_index()['var_diff_agg_i'].describe()\n",
    "                bin_vals = sorted_s.groupby('n')['var_diff_qi'].describe()\n",
    "\n",
    "                xn = bin_vals.index.values\n",
    "#                 ax.plot([xn.min(), xn.max()], [agg_vals['50%'], agg_vals['50%']], color = colors[k], alpha = .6, zorder = 10)\n",
    "                ax.plot([xn.min(), xn.max()], [.0002/xn.min(), .0002/xn.max()], color = '.5', alpha = .6, zorder = 10, lw = 1, label = '1/n dependence', linestyle = '--')\n",
    "                ax.fill_between(xn, bin_vals['25%'], bin_vals['75%'], color = colors[k], alpha = .35, zorder = 10, label = sizes + dist)\n",
    "                ax.plot(xn, bin_vals['50%'], color = 'w', zorder = 10, marker = '.', lw = 0, alpha = .7)\n",
    "\n",
    "#                 ax.legend(loc = (1, 0))\n",
    "    #         [ax.axvline(l, linestyle = '--') for l in sorted_s.groupby(['q']).count().iloc[:, 0].cumsum().values]\n",
    "            ax.set_xscale('log')\n",
    "#                 ax.set_xlim(5, 2e5)\n",
    "            ax.set_xlim(1, 1e4)\n",
    "\n",
    "            ax.set_yscale('log')\n",
    "            ax.set_ylim(1e-8, 10)\n",
    "            ax.set_ylabel('variance '+r'$\\sigma^2$', fontsize = 12)\n",
    "            ax.set_xlabel('log(n)', fontsize = 12)\n",
    "\n",
    "#             ax.legend().remove()\n",
    "\n",
    "plt.savefig('./../../../paper1_writing/figures/sigma_vs_n_szdists.png', dpi = 400)\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como se mueven Q y n al mismo tiempo. \n",
    "# En teoria esta bien, peor en la practica hay mucha volatilidad como para verlo lindo.\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, figsize = (12, 5))\n",
    "\n",
    "# # Q_ = 20\n",
    "# for l, Q_ in enumerate([10, 20]):\n",
    "#     for i, sizes in enumerate(['pareto', 'logn']):\n",
    "#         for j, dist in enumerate(['emp_szd_T16']):\n",
    "#             ax = axs[i]\n",
    "#             ax.set_title(sizes +', '+ dist)\n",
    "#             result = data2[i][j]\n",
    "#             result = result.loc[result.Q == Q_]\n",
    "\n",
    "#             y = 'var_diff_qi'\n",
    "\n",
    "#             # Merge the Ns\n",
    "#             bins, ns = get_n([x_pareto, x_logn_clip3, x_logn_clip3_90][i], Q_)\n",
    "#             ns = pd.DataFrame([range(Q_), ns], index = ['q', 'n']).T\n",
    "#             result = result.merge(ns)\n",
    "#             result['log_n'] = np.log10(result.n)\n",
    "#     #         result['log_var_diff_qi'] = np.log10(result.var_diff_qi)\n",
    "\n",
    "#             sorted_ = result.sort_values(by = ['dist','s', 'q', y])\n",
    "#             s = sorted_.s.unique()[0]\n",
    "            \n",
    "#             sorted_s = sorted_.loc[sorted_.s == s]\n",
    "# #             sorted_s.reset_index()[[y]].plot(ax = ax, marker = '.', lw = 0, c = colors[k])\n",
    "# #                     sorted_s.reset_index()[['var_diff_agg_i']].plot(ax = ax, marker = '.', lw = 0, c = colors[k], alpha = .1, legend = False)\n",
    "#             agg_vals = sorted_s.reset_index()['var_diff_agg_i'].describe()\n",
    "#             bin_vals = sorted_s.groupby('n')['var_diff_qi'].describe()\n",
    "\n",
    "#             xn = bin_vals.index.values\n",
    "# #             ax.plot([xn.min(), xn.max()], [agg_vals['50%'], agg_vals['50%']], color = colors[k], alpha = .6, zorder = 10)\n",
    "# #             ax.plot([xn.min(), xn.max()], [1/xn.min(), 1/xn.max()], color = '.5', alpha = .6, zorder = 10)\n",
    "#             ax.fill_between(xn, bin_vals['25%'], bin_vals['75%'], color = colors[k], alpha = .35, zorder = 10)\n",
    "#             ax.plot(xn, bin_vals['50%'], color = ['w','k'][l], zorder = 10, marker = '.', lw = 0)\n",
    "\n",
    "# #             ax.legend(Qs, loc = (1, 0))\n",
    "#     #         [ax.axvline(l, linestyle = '--') for l in sorted_s.groupby(['q']).count().iloc[:, 0].cumsum().values]\n",
    "#             ax.set_xscale('log')\n",
    "#             ax.set_xlim(1, 1e5)\n",
    "\n",
    "#             ax.set_yscale('log')\n",
    "# #             ax.set_ylim(1e-7, 1)\n",
    "\n",
    "# plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como se mueven Q y n al mismo tiempo. \n",
    "# En teoria esta bien, peor en la practica hay mucha volatilidad como para verlo lindo.\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize = (15, 5))\n",
    "    \n",
    "for i, sizes in enumerate(['pareto', 'logn90', 'logn']):\n",
    "    for j, dist in enumerate(['emp_szd_T16']):\n",
    "        ax = axs[i]\n",
    "        ax.set_title(sizes +', '+ dist)\n",
    "        result = full_data.loc[(full_data.sizes == sizes) & (full_data.dist == dist)]\n",
    "        result = result.loc[result.Q == 20]\n",
    "\n",
    "        y = 'var_diff_qi'\n",
    "\n",
    "        # Merge the Ns\n",
    "        bins, ns = get_n([x_pareto, x_logn_clip3, x_logn_clip3_90][i], Q_)\n",
    "        ns = pd.DataFrame([range(Q_), ns], index = ['q', 'n']).T\n",
    "        result = result.merge(ns)\n",
    "        result['log_n'] = np.log10(result.n)\n",
    "#         result['log_var_diff_qi'] = np.log10(result.var_diff_qi)\n",
    "\n",
    "        sorted_ = result.sort_values(by = ['dist','s', 'q', y])\n",
    "        s = sorted_.s.unique()[0]\n",
    "\n",
    "        sorted_s = sorted_.loc[sorted_.s == s]\n",
    "#             sorted_s.reset_index()[[y]].plot(ax = ax, marker = '.', lw = 0, c = colors[k])\n",
    "#                     sorted_s.reset_index()[['var_diff_agg_i']].plot(ax = ax, marker = '.', lw = 0, c = colors[k], alpha = .1, legend = False)\n",
    "        agg_vals = sorted_s.reset_index()['var_diff_agg_i'].describe()\n",
    "        bin_vals = sorted_s.groupby('n')['var_diff_qi'].describe()\n",
    "\n",
    "        xn = bin_vals.index.values\n",
    "#             ax.plot([xn.min(), xn.max()], [agg_vals['50%'], agg_vals['50%']], color = colors[k], alpha = .6, zorder = 10)\n",
    "#             ax.plot([xn.min(), xn.max()], [1/xn.min(), 1/xn.max()], color = '.5', alpha = .6, zorder = 10)\n",
    "        ax.fill_between(xn, bin_vals['25%'], bin_vals['75%'], color = colors[k], alpha = .35, zorder = 10)\n",
    "        ax.plot(xn, bin_vals['50%'], color = 'k', zorder = 10, marker = '.', lw = 0)\n",
    "\n",
    "#             ax.legend(Qs, loc = (1, 0))\n",
    "#         [ax.axvline(l, linestyle = '--') for l in sorted_s.groupby(['q']).count().iloc[:, 0].cumsum().values]\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlim(1, 1e5)\n",
    "\n",
    "        ax.set_yscale('log')\n",
    "#             ax.set_ylim(1e-7, 1)\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log10(result['var_diff_qi']/result.Q), 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Superplot\n",
    "\n",
    "# Choose \n",
    "#  - size dist\n",
    "#  - growth rates\n",
    "#  - Q\n",
    "\n",
    "Q_ = 25;\n",
    "\n",
    "i = 1\n",
    "j = 0\n",
    "sizes = ['pareto', 'logn', 'logn90'][i]\n",
    "x1 = [x_pareto, x_logn_clip3, x_logn_clip3_90][i]\n",
    "dist = ['emp_szd_T16_clip.8','emp_szd_T16', 'lapl', 'norm'][j]\n",
    "\n",
    "\n",
    "result = full_data.loc[(full_data.sizes == sizes) & (full_data.dist == dist)]\n",
    "result = result.loc[result.Q == Q_]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize = (12, 9))\n",
    "\n",
    "\n",
    "##########\n",
    "# PLOT 1 #\n",
    "##########\n",
    "\n",
    "ax = axs[0][0]\n",
    "ax.set_title('Variance vs '+r'$n_q$', fontsize = 15)\n",
    "\n",
    "\n",
    "# Merge the Ns\n",
    "bins, ns = get_n(x1, Q_)\n",
    "ns = pd.DataFrame([range(Q_), ns], index = ['q', 'n']).T\n",
    "result = result.merge(ns)\n",
    "result['log_n'] = np.log10(result.n)\n",
    "# result['var_diff_qi/Q'] = result['var_diff_qi']/result.Q\n",
    "y = 'var_diff_qi'\n",
    "\n",
    "sorted_ = result.sort_values(by = ['dist','s', 'q', y], ascending = [True, False, False, True])\n",
    "\n",
    "Ss = sorted_.s.unique()[::-2]\n",
    "for k, s in enumerate(Ss):\n",
    "    sorted_s = sorted_.loc[sorted_.s == s]\n",
    "    agg_vals = sorted_s.reset_index()['var_diff_agg_i'].describe()\n",
    "    bin_vals = sorted_s.groupby('n')['var_diff_qi'].describe()\n",
    "\n",
    "    xn = bin_vals.index.values\n",
    "    ax.plot([xn.min(), xn.max()], [agg_vals['50%'], agg_vals['50%']], color = colors[k], alpha = .6, zorder = 10)\n",
    "    ax.fill_between(xn, bin_vals['25%'], bin_vals['75%'], color = colors[k], alpha = .35, zorder = 10)\n",
    "    ax.plot(xn, bin_vals['50%'], color = 'w', zorder = 10, marker = '.', lw = 0)\n",
    "\n",
    "markerline, stemlines, baseline = ax.stem(xn, bin_vals['50%'], '.5', markerfmt = 'None', bottom = 0)\n",
    "plt.setp(stemlines, 'linestyle', 'dashed')\n",
    "\n",
    "ax.legend().remove()\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(1, 2e5)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylim(1e-8, 10)\n",
    "ax.set_ylabel('variance '+r'$\\sigma^2$', fontsize = 15)\n",
    "\n",
    "\n",
    "##########\n",
    "# PLOT 2 #\n",
    "##########\n",
    "ymax = 1.1\n",
    "xmax = np.log10(2e5)\n",
    "\n",
    "ax = axs[1][0]\n",
    "# for i, Q in enumerate([10, 20, 30]):\n",
    "#     ns = get_n(x_pareto, Q)[1]\n",
    "#     ax.plot(np.log10(ns), .1 + 0.9*(np.arange(Q)/Q), marker = '.', c = '#ff7f0e', alpha = [1, .8, .6][i], label = 'Pareto, Q = '+str(Q))\n",
    "    \n",
    "# for i, Q in enumerate([10, 20, 30]):\n",
    "Q = Q_\n",
    "ns = get_n(x1, Q)[1]\n",
    "pct_levels = (np.arange(Q) + .5)/Q\n",
    "ax.plot(np.log10(ns), pct_levels, marker = 'o', c = '#1f77b4', label = sizes + ', Q = '+str(Q))\n",
    "# ax.stem(np.log10(ns), pct_levels, '.5', markerfmt = 'None', bottom = 1)\n",
    "ax.hlines(pct_levels, xmax, np.log10(ns), color='.5', alpha = .6, lw = 1)\n",
    "ax.vlines(np.log10(ns), ymax, pct_levels, color='.5', alpha = .6, lw = 1)\n",
    "\n",
    "ax.set_ylabel('percentile', fontsize = 15)\n",
    "ax.set_xlabel('log(n)', fontsize = 15)\n",
    "ax.set_ylim(0, ymax)\n",
    "ax.set_xlim(0, xmax)\n",
    "ax.legend().remove()\n",
    "\n",
    "ax.annotate(r'$n_q$ from size dist.', xy=(1.5, .2), ha=\"center\", fontsize=13)\n",
    "\n",
    "\n",
    "##########\n",
    "# PLOT 3 #\n",
    "##########\n",
    "\n",
    "ax = axs[1][1]\n",
    "# Q = Q_\n",
    "pct_levels = (np.arange(Q) + .5)/Q\n",
    "# plot_levels_reflex(pct_levels, ax)\n",
    "\n",
    "ax.hlines(pct_levels, 0, 1 - pct_levels, color='.5', alpha = .6, lw = 1)\n",
    "ax.vlines(1 - pct_levels, ymax, pct_levels, color='.5', alpha = .6, lw = 1)\n",
    "ax.plot(pct_levels, len(pct_levels)*[1.08], '^', markersize = 8, c = '.5')\n",
    "\n",
    "ax.set_ylim(0, ymax)\n",
    "ax.set_xlim(0, 1)\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "##########\n",
    "# PLOT 4 #\n",
    "##########\n",
    "\n",
    "ax = axs[0][1]\n",
    "ax.set_title('Variance vs q '+r'$(\\sigma^2_q)$', fontsize  =15)\n",
    "\n",
    "for k, s in enumerate(Ss):\n",
    "    sorted_s = sorted_.loc[sorted_.s == s]\n",
    "    sorted_s.reset_index()[[y]].plot(ax = ax, marker = '.', lw = 0, c = colors[k])\n",
    "#                     sorted_s.reset_index()[['var_diff_agg_i']].plot(ax = ax, marker = '.', lw = 0, c = colors[k], alpha = .1, legend = False)\n",
    "    agg_vals = sorted_s.reset_index()['var_diff_agg_i'].describe()\n",
    "    ax.fill_between(range(len(sorted_s)), agg_vals['25%'], agg_vals['75%'], color = colors[k], alpha = .35, zorder = 10)\n",
    "    \n",
    "\n",
    "[ax.axvline(l, color = '.5', lw = 1) for l in sorted_s.groupby(['q']).count().iloc[:, 0].cumsum().values]\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylim(1e-8, 10)\n",
    "ax.legend([str(2*s) for s in Ss]+[r'aggregate $\\sigma^2$'], title='shock \\n magnification', loc = (1.02, 0))     \n",
    "\n",
    "ax.xaxis.set_ticks(np.arange(0, (Q)*100, 100) + 100/2)\n",
    "ax.xaxis.set_ticklabels(np.arange(Q) + 1, ha = 'right')\n",
    "\n",
    "plt.savefig('./../../../paper1_writing/figures/n_to_q_tranformation.png', dpi = 400)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Older"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax = axs[1][0]\n",
    "# for i, Q in enumerate([10, 20, 30]):\n",
    "#     ns = get_n(x_pareto, Q)[1]\n",
    "#     ax.plot(np.log10(ns), .1 + 0.9*(np.arange(Q)/Q), marker = '.', c = '#ff7f0e', alpha = [1, .8, .6][i], label = 'Pareto, Q = '+str(Q))\n",
    "    \n",
    "for i, Q in enumerate([10, 20, 30]):\n",
    "    ns = get_n(x_logn_clip3, Q)[1]\n",
    "    ax.plot(np.log10(ns), np.arange(Q)/Q, marker = '.', c = '#1f77b4', alpha = [1, .8, .6][i], label = 'Lognormal, Q = '+str(Q))\n",
    "\n",
    "ax.set_ylabel('percentile')\n",
    "ax.set_xlabel('log(n)')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlim(np.log10(2), np.log10(2e5))\n",
    "ax.legend()\n",
    "# plt.savefig('./../../../paper1_writing/figures/quantile_logn.png', dpi = 400)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "results = []\n",
    "for j, x1 in enumerate([x_pareto, x_logn_clip3]):\n",
    "    sizes = ['pareto', 'logn90', 'logn'][j]\n",
    "    for k, dist in enumerate(['sbtn', 'lapl', 'norm']):        \n",
    "        filename = './../../data/processed/exp_var_'+dist+'_1s_'+sizes+'.csv'\n",
    "        results += [pd.read_csv(filename)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (12, 4.5))\n",
    "\n",
    "Q_ = 25\n",
    "s = .1\n",
    "\n",
    "for j, x1 in enumerate([x_pareto, x_logn_clip3]):\n",
    "    N = len(x1)\n",
    "    sizes = ['pareto', 'logn'][j]\n",
    "    for k, dist in enumerate(['sbtn', 'lapl', 'norm']):\n",
    "        ax = axs[j]\n",
    "        df = results[3*j + k][['Q','q', 'var_diff_qi','s']]\n",
    "        df = df.loc[(df.Q == Q_) & (df.s == s)]\n",
    "        df['t'] = df['var_diff_qi']/(df['s']**2)\n",
    "        bins, ns = get_n(x1, Q_)\n",
    "        ns = pd.DataFrame([range(Q_), ns], index = ['q', 'n']).T\n",
    "        df = df.merge(ns)\n",
    "        df['log_n'] = np.log10(df.n)\n",
    "        df['log_var_diff_qi'] = np.log10(df.var_diff_qi)\n",
    "\n",
    "        frac = 1; alpha = .05\n",
    "#         frac = .1; alpha = .5\n",
    "        data=df.sample(frac = frac); data.log_n = data.log_n + np.random.normal(0, 0.03, len(data))\n",
    "        ax.scatter(x=data.log_n.values, y=data.log_var_diff_qi.values, alpha = alpha, marker = '.', \n",
    "                   label = ['Normal', 'Laplace', 'Subbotin'][k], color = ['#1f77b4', '#ff7f0e'][j])\n",
    "        ax.set_title(['Pareto', 'Lognormal'][j]+' size dist.')\n",
    "        ax.set_xlabel(r'$log(n_q)$', fontsize = 13)\n",
    "        ax.set_ylabel(r'$log(\\sigma^2_{logdiff})$', fontsize = 13)\n",
    "        ax.set_xlim(-0.1, 5.1)\n",
    "        ax.set_ylim(-4.8, -1)\n",
    "        x_ = np.arange(0, 6, 1)\n",
    "    ax.plot(x_, -x_-.5, linestyle = '--', color = '.5', label = r'$1/\\sqrt{n}$ reference')\n",
    "    ax.legend()\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('./../../../paper1_writing/figures/sigma_logn_sizedist.png', dpi = 400)\n",
    "plt.show()\n",
    "# colors:\n",
    "# ['#1f77b4',\n",
    "#  '#ff7f0e']\n",
    "\n",
    "#         y = 't'\n",
    "#         sorted_ = result.sort_values(by = ['dist','s', 'q', y])\n",
    "#         [ax.axvline(l, linestyle = '--') for l in sorted_.groupby(['dist','s', 'q']).count().iloc[:, 0].cumsum().values]\n",
    "#         [ax.axvline(l, lw = 2) for l in sorted_.groupby(['s','Q']).count().iloc[:, 0].cumsum().values]\n",
    "#         sorted_.reset_index()[[y]].plot(ax = ax, marker = '.', lw = 0)\n",
    "#         ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize = (12, 6))\n",
    "\n",
    "Q_ = 25\n",
    "\n",
    "for j, x1 in enumerate([x_pareto, x_logn_clip3]):\n",
    "# for j, x1 in enumerate([x_logn_clip3]):\n",
    "    N = len(x1)\n",
    "    sizes = ['pareto', 'logn'][j]\n",
    "    for k, dist in enumerate(['sbtn', 'lapl', 'norm']):\n",
    "        ax = axs[j][k]\n",
    "        df = results[3*j + k][['Q','q', 'var_diff_qi','s']]\n",
    "        df = df.loc[(df.Q == Q_)]\n",
    "        df['t'] = df['var_diff_qi']/(df['s']**2)\n",
    "        bins, ns = get_n(x1, Q_)\n",
    "        ns = pd.DataFrame([range(Q_), ns], index = ['q', 'n']).T\n",
    "        df = df.merge(ns)\n",
    "        df['log_n'] = np.log10(df.n)\n",
    "\n",
    "        frac = 1; alpha = .05\n",
    "        for s in [.1, .3, .5]:\n",
    "            df['log_var_diff_qi'] = np.log10(df.var_diff_qi) - np.log10(s**2)\n",
    "            data = df[df.s == s].sample(frac = frac); data.log_n = data.log_n + np.random.normal(0, 0.03, len(data))\n",
    "            ax.scatter(x=data.log_n.values, y=data.log_var_diff_qi.values, alpha = alpha, marker = '.', label = str(s))\n",
    "        ax.set_title(['Normal', 'Laplace', 'Subbotin'][k]+' logshocks. '+['Pareto', 'Lognormal'][j]+' size dist.')\n",
    "        ax.legend()\n",
    "        ax.set_xlabel(r'$log(n_q)$', fontsize = 13)\n",
    "        ax.set_ylabel(r'$log(\\sigma_{logdiff} / s^2)$', fontsize = 13)\n",
    "        ax.set_xlim(-0.1, 5.1)\n",
    "        ax.set_ylim(-3, 2)\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('./../../../paper1_writing/figures/sigma_logn_s.png', dpi = 400)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['#1f77b4',\n",
    " '#ff7f0e',\n",
    " '#2ca02c',\n",
    " '#d62728',\n",
    " '#9467bd',\n",
    " '#8c564b',\n",
    " '#e377c2',\n",
    " '#7f7f7f',\n",
    " '#bcbd22',\n",
    " '#17becf']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
