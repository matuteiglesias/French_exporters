{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy.stats import pareto\n",
    "from scipy.special import erf\n",
    "\n",
    "# The size dists are:\n",
    "#  - Lognormal clipped x > 3. \n",
    "sigma = 1.2810683494198207 # 1.3149476902828778\n",
    "mu = 4.536908110675739 # 4.470439741406725\n",
    "# 11.5% of guys that would be below the .3 threshold.\n",
    "z = (mu - 3)/sigma\n",
    "cum_th = 1 - .5*(1 + erf(z/np.sqrt(2)))\n",
    "\n",
    "# We'll try different N's, until we can match the avg level of France imports \n",
    "\n",
    "N = int(1e5)\n",
    "N_ = int(round(N/(1 - cum_th))) # We use a larger N ..\n",
    "draw = np.random.normal(mu, sigma, N_) # so that approximately we'll have N guys above x = 3\n",
    "draw = np.sort(draw)[-N:]\n",
    "\n",
    "# Now we can have the n(Q, q)\n",
    "def get_n(x1, Q):\n",
    "    x_lin = np.power(10, x1)\n",
    "    bins = pd.cut(pd.Series(np.cumsum(x_lin)), Q)\n",
    "    ns = bins.value_counts().values\n",
    "    return bins, ns\n",
    "\n",
    "# From the theoretical N and the ppf we can know the theoretical quantiles\n",
    "x_logn_clip3 = np.array([norm.ppf(q, mu, sigma) for q in np.arange(0, 1, 1/N_) + .5/N_])\n",
    "x_logn_clip3 = x_logn_clip3[(-N - 1):-1]\n",
    "\n",
    "## N tail for pareto and lognormal tail\n",
    "N_tail = get_n(x_logn_clip3, 10)[1][1:].sum()\n",
    "\n",
    "n = N_tail\n",
    "x_logn_clip3_90 = x_logn_clip3[-N_tail:]\n",
    "\n",
    "# PARETO\n",
    "z_0 = -1.1042021 #-1.1771\n",
    "# value_qs_1 = x_logn_clip3_90.min() # 6.761 in the original fit\n",
    "value_qs_1 = 6.67465\n",
    "\n",
    "norm = 1.375\n",
    "x1 = np.array([pareto.ppf(b = -z_0, scale = 10**value_qs_1, q = q) for q in np.arange(0, 1, 1/(norm*N_tail)) + .5/(norm*N_tail)])\n",
    "np.log10(pareto.rvs(b = -z_0, size = n, scale = 10**value_qs_1) + 1)\n",
    "x1 = x1[int(-norm*N_tail - 1):-1]\n",
    "\n",
    "x_pareto = np.log10(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emp_nqs = np.round(nq.sort_values()).astype(int)\n",
    "ss = np.arange(0.1, .8, .2)\n",
    "M = 100\n",
    "\n",
    "T = 17\n",
    "Q = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n"
     ]
    }
   ],
   "source": [
    "### Experiments (gaussian and laplace deviations from mean)\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "for dist in ['norm', 'lapl']:\n",
    "    for j, size_dist in enumerate([x_logn_clip3, x_logn_clip3_90, x_pareto]):\n",
    "        print('*')\n",
    "        sdist_name = ['Logn', 'Logn90', 'Pareto'][j]\n",
    "        bins, partition_ns = get_n(size_dist, Q)\n",
    "        for q, part in enumerate(bins.unique()):\n",
    "            x0 = pd.Series(size_dist).loc[bins == part].values\n",
    "            n = partition_ns[q]\n",
    "            for s in ss:\n",
    "                for m in range(M):\n",
    "                    if dist == 'norm':\n",
    "                        shocks = np.random.normal(0, s, (n, T))\n",
    "                    elif dist == 'lapl':\n",
    "                        shocks = np.random.laplace(0, s, (n, T))/np.sqrt(2)\n",
    "    #                 values = np.log10(np.power(10, shocks).sum(0)/n) #M?\n",
    "                    # same as before but now x0 is a vector of sizes in the quantile, determined by the size dist, N and the Q chosen.\n",
    "                    values = np.log10(np.power(10, x0[:, None] + shocks).sum(0)/np.power(10, x0[:, None]).sum(0)) #M?\n",
    "    #             t += [np.power(10, x0 + x1).sum()/(n*10**mu0)]\n",
    "\n",
    "\n",
    "                    results += [[dist, sdist_name, s, n, m, values.mean(), values.std()]]\n",
    "\n",
    "sdist_result = pd.DataFrame(results, columns = ['dist', 'size_dist', 's', 'nq', 'repeat', 'mean', 'std'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
