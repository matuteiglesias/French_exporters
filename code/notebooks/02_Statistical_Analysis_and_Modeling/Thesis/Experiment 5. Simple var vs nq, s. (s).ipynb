{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./../../data/processed/ID_Y.csv')\n",
    "# df = pd.read_csv('./../../data/processed/.csv')\n",
    "\n",
    "sales = df.loc[df.IMPORT == 0].groupby(['ID', 'YEAR'])['VART'].sum().unstack()\n",
    "sales = sales.loc[sales.sum(1).sort_values().index]\n",
    "\n",
    "logsales = np.log10(sales)\n",
    "demlogsales = logsales.subtract(logsales.mean(1), axis = 0)\n",
    "\n",
    "sizes = sales.loc[sales.sum(1).sort_values().index].sum(1)\n",
    "\n",
    "Q = 10\n",
    "parts = pd.cut(sizes.cumsum()/sizes.sum(), Q, labels = range(Q)).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    98643\n",
       "1     4212\n",
       "2     1414\n",
       "3      635\n",
       "4      319\n",
       "5      168\n",
       "6       92\n",
       "7       46\n",
       "8       17\n",
       "9        5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Effective Nq\n",
    "eff_nq = sales.groupby(parts).count().mean(1).round().astype(int)\n",
    "eff_nq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import norm\n",
    "# from scipy.stats import norm\n",
    "# from scipy.stats import pareto\n",
    "from scipy.special import erf\n",
    "\n",
    "#  - Lognormal clipped x > 3. \n",
    "sigma = 1.2810683494198207 # 1.3149476902828778\n",
    "mu = 4.536908110675739 # 4.470439741406725\n",
    "# 11.5% of guys that would be below the .3 threshold.\n",
    "z = (mu - 3)/sigma\n",
    "cum_th = 1 - .5*(1 + erf(z/np.sqrt(2)))\n",
    "\n",
    "# emp_nq_med = nq.groupby(level = 0).median()\n",
    "N = int(eff_nq.sum().round())\n",
    "\n",
    "N_ = int(round(N/(1 - cum_th))) # We use a larger N ..\n",
    "# From the theoretical N and the ppf we can know the theoretical quantiles\n",
    "x_logn_clip3 = np.array([norm.ppf(q, mu, sigma) for q in np.arange(0, 1, 1/N_) + .5/N_])\n",
    "x_logn_clip3 = x_logn_clip3[(-N - 1):-1]\n",
    "\n",
    "\n",
    "T = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dem = logsales.sub(logsales.mean(1), axis = 0)\n",
    "sample_shocks = dem.loc[dem.count(1) > 1].unstack().dropna() # (1.6 m real shocks)\n",
    "micro_s = logsales.sub(logsales.mean(1), axis=0).unstack().std()\n",
    "zero_shock = pd.DataFrame(pd.concat(T * [pd.Series(x_logn_clip3)], axis = 1))\n",
    "zero_shock.columns = sales.columns\n",
    "\n",
    "out_list = []\n",
    "\n",
    "n = 5\n",
    "Q = 10\n",
    "\n",
    "for m in range(n):\n",
    "    print(m)\n",
    "    for s in [.02, .05, .1, .25, .5]:\n",
    "\n",
    "#         df_bs = sales.sample(frac = .5)\n",
    "#         df_bs = df_bs.loc[df_bs.sum(1).sort_values().index] #sorting\n",
    "\n",
    "#         logsales = np.log10(sales)\n",
    "        simu_shocks = pd.DataFrame((s/micro_s)*np.random.choice(sample_shocks.values, zero_shock.shape))\n",
    "        simu_shocks.columns = sales.columns\n",
    "\n",
    "        total = np.power(10, zero_shock + simu_shocks)\n",
    "        base = np.power(10, zero_shock) # Is really frozen in this case\n",
    "        noise = np.power(10, zero_shock + simu_shocks) - np.power(10, zero_shock)\n",
    "        \n",
    "        total['q'] = pd.cut(total.sum(1).cumsum(), Q, labels = range(Q))\n",
    "\n",
    "        noise_qs = noise.groupby(total['q']).sum()\n",
    "        base_qs = base.groupby(total['q']).sum()\n",
    "        yqs = noise_qs + base_qs\n",
    "        \n",
    "        nqs = total['q'].value_counts().values\n",
    "#         lognqs = np.log10(nqs)\n",
    "        \n",
    "        out = pd.concat([yqs.var(1), noise_qs.var(1), base_qs.var(1)], axis = 1)\n",
    "        out.columns = ['yqs_var', 'noise_var', 'base_var']\n",
    "        out['q'] = range(Q); out['m'] = m; out['nqs'] = nqs; out['s'] = s;\n",
    "\n",
    "        out_list += [out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_result = pd.concat(out_list).reset_index(drop = True)\n",
    "# data = bs_result.groupby(['q', 's']).agg(['mean', 'std']).drop('m', axis = 1)\n",
    "data = bs_result.groupby(['q', 's']).median().drop('m', axis = 1)\n",
    "\n",
    "def percentile_lo (x): \n",
    "    return np.percentile(x, q=10)\n",
    "def percentile_hi (x): \n",
    "    return np.percentile(x, q=90)\n",
    "\n",
    "data_m = bs_result.groupby(['q', 's']).median().drop('m', axis = 1)\n",
    "data_lo = bs_result.groupby(['q', 's']).agg(percentile_lo).drop('m', axis = 1)\n",
    "data_hi = bs_result.groupby(['q', 's']).agg(percentile_hi).drop('m', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save:\n",
    "\n",
    "data.to_csv('./')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
